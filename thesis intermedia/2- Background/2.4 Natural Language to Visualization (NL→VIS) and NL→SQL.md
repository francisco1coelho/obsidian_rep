
- Descreve abordagens anteriores:
    
    - NL→SQL: _Text2SQL_, _Picard_, _RAT-SQL_, _SQL-Palm_, etc.
        
    - NL→VIS: _DataTone_, _Datamations_, _Vis2Text_, _ChartGPT_.
        
- Mostra como estas tecnologias tentam mapear intenções do utilizador para gráficos ou queries.
    
- Discute vantagens e limitações: interpretabilidade, ambiguidade, dependência da ontologia de dados.


Para o meu estágio vou ter que fazer alguma coisa como o DataTone, vou ter que usar a biblioteca NL4DV muito provavelmente (falar disto no state of art)



---

## 2.4 Natural Language to Visualization (NL→VIS) and NL→SQL

The ability to transform natural language (NL) queries into executable visual or analytical representations has long been a goal of human–computer interaction research. This paradigm, referred to as **Natural Language to Visualization (NL→VIS)** or **Natural Language to Query (NL→SQL)**, aims to enable users to explore data and generate insights without writing code or understanding database schemas. In the context of real-time analytics, such as contact center dashboards, these approaches serve as the conceptual foundation for the system developed in this dissertation.

---

### 2.4.1 From Natural Language to Structured Queries (NL→SQL)

The earliest research in this domain focused on translating natural language questions into **Structured Query Language (SQL)**, allowing non-technical users to query relational databases conversationally. This field, known as **Text-to-SQL**, uses natural language understanding (NLU) to parse a sentence, identify entities and relationships, and construct an equivalent SQL statement that retrieves the requested data.

Initial approaches were rule-based, relying on handcrafted grammars and pattern matching (Popescu et al., 2003). With the advent of deep learning, neural models such as **Seq2Seq** (Iyer et al., 2017) and **Transformer-based architectures** like **RAT-SQL** (Wang et al., 2020) introduced semantic parsing guided by database schema awareness. These models leverage **schema linking**, where the model maps words from the question (e.g., “average duration”) to table columns (“call_duration”), ensuring syntactic and semantic coherence between user intent and database structure.

Recent progress, especially with instruction-tuned LLMs such as GPT-4, has demonstrated that large-scale pretraining substantially improves **zero-shot Text-to-SQL** capabilities. These models can generalize to new domains and schemas with minimal fine-tuning, provided they receive schema context and examples within the prompt (Zhang et al., 2023). Commercial applications, such as **Microsoft Copilot for Power BI** and **Google Looker’s NLQ**, already use this technique to let users ask questions like _“show me total calls by agent for today”_, which are internally transformed into SQL queries over data warehouses.

In summary, NL→SQL techniques enable **semantic parsing of natural language into structured queries**, establishing the theoretical foundation for higher-level mappings from language to visualization layouts and dashboard configurations.

---

### 2.4.2 From Queries to Visual Representations (NL→VIS)

While NL→SQL focuses on retrieving data, **Natural Language to Visualization (NL→VIS)** extends the pipeline to include **visual reasoning** — selecting appropriate chart types, layouts, and encodings based on user intent and data semantics. The goal is not only to answer “what data to show” but also “how to show it.”

Early systems such as **DataTone** (Gao et al., 2015) introduced ambiguity management, allowing users to refine results when the system was uncertain about their intent. Later projects like **Datamations** (Wongsuphasawat et al., 2021) used animation to explain how data transformations map to visual outcomes, enhancing interpretability.  
Recent LLM-based systems, such as **ChartGPT** (Luo et al., 2023) and **Vega-Lite Generators** using GPT-4 APIs, can directly translate text prompts (e.g., _“plot average wait time per queue as a bar chart”_) into full visualization specifications (e.g., Vega-Lite or Plotly JSON). These models leverage structured output techniques described in Section 2.3 — typically generating a JSON specification where each field corresponds to a visual encoding, axis, or metric.

The NL→VIS pipeline generally consists of three stages:

1. **Intent extraction** — identify what the user wants to analyze (e.g., metrics, time period, grouping).
    
2. **Data mapping** — determine which dataset fields or metrics correspond to those concepts.
    
3. **Visualization encoding** — select chart type and layout based on data type (quantitative, categorical) and analytical goal (comparison, trend, distribution).
    

Modern implementations increasingly rely on **LLMs as multi-step planners**, capable of decomposing user requests into these three reasoning stages and generating visualization code or configurations accordingly (Zhao et al., 2023).

---

### 2.4.3 Challenges and Relevance to This Work

Despite progress, both NL→SQL and NL→VIS face significant challenges:

- **Ambiguity in language** — the same request (“average call duration”) can map to multiple metrics (AHT, TalkTime, HandleTime).
    
- **Schema and ontology dependence** — models must understand the structure and meaning of available data sources.
    
- **Faithfulness and correctness** — generated outputs must accurately reflect user intent and data semantics, not just produce syntactically valid queries.
    
- **Feedback and refinement** — systems must support interactive correction (“add occupancy”, “remove ASA”) without breaking state continuity.
    

This dissertation leverages the principles of NL→VIS but tailors them for **real-time, semantic, and role-aware dashboards**. Instead of mapping natural language to SQL or visualization code directly, the proposed system maps it to a **domain-specific JSON configuration** that represents the structure and semantics of a live dashboard. Each configuration element — metrics, widgets, filters — corresponds to entities defined in the **semantic layer** of the contact center analytics platform (see Section 2.2).

By combining structured LLM output, ontology-based validation, and conversational refinement loops, this approach bridges the gap between user intent and real-time data visualization. In essence, it extends NL→VIS from the static analytics domain into **dynamic, streaming-aware contexts**, allowing dashboards to adapt instantly to natural language inputs.

---

### References

- Popescu, A., Etzioni, O., & Kautz, H. (2003). _Towards a theory of natural language interfaces to databases._ Proceedings of IUI’03. https://dl.acm.org/doi/10.1145/604045.604070
    
- Iyer, S., Konstas, I., Cheung, A., & Zettlemoyer, L. (2017). _Learning a neural semantic parser from user feedback._ ACL 2017. https://aclanthology.org/P17-1013
    
- Wang, B., Shin, R., Liu, X., Polozov, O., & Richardson, M. (2020). _RAT-SQL: Relation-aware schema encoding and linking for text-to-SQL parsers._ ACL 2020. https://arxiv.org/abs/1911.04942
    
- Zhang, Y., et al. (2023). _Are Large Language Models Good at Text-to-SQL? A Comprehensive Evaluation._ arXiv preprint. https://arxiv.org/abs/2308.15363
    
- Gao, T., et al. (2015). _DataTone: Managing Ambiguity in Natural Language Interfaces for Data Visualization._ CHI 2015. https://dl.acm.org/doi/10.1145/2702123.2702605
    
- Wongsuphasawat, K., et al. (2021). _Datamations: Animated explanations of data analysis pipelines._ IEEE VIS 2021. https://arxiv.org/abs/2104.12327
    
- Luo, X., et al. (2023). _ChartGPT: Leveraging Large Language Models for Natural Language Visualization Generation._ arXiv preprint. https://arxiv.org/abs/2305.15387
    
- Zhao, W., et al. (2023). _AutoVis: Natural Language to Visualization via LLM Planning._ arXiv preprint. https://arxiv.org/abs/2310.03593