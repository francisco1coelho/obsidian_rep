[[State of art]]

### ==verificar que abordagem devo de seguir==
# **Foundations and Related Technologies — Stage 2: Semantic Mapping**

## **Stage Introduction**

The second stage of the **NL→Dash** pipeline, **Semantic Mapping**, is responsible for translating the interpreted user intent into a structured and **semantically consistent representation of metrics, dimensions, and filters**. After the Prompt/Intent stage identifies the intent (e.g., _create dashboard for queue performance_), Semantic Mapping ensures that the terminology used by the user is **aligned with the system’s internal data model**.

This process guarantees that terms such as “average wait time” or “AHT” are mapped to the correct internal **Key Performance Indicators (KPIs)**, calculation logic, and database fields. The outcome of this phase is a **semantically aligned JSON structure**, ensuring that every metric and dimension referenced by the user corresponds to an actual data entity within the analytics warehouse.

Semantic Mapping thus plays a critical role in **bridging natural language and data semantics**, reducing ambiguity and maintaining the consistency of dashboards generated through language-driven interaction. In practical terms, it acts as a **semantic layer** that formalizes and validates metric definitions, providing a shared vocabulary across the NL→Dash pipeline.

---

## **Technological Analysis**

Several technologies and frameworks implement similar principles of semantic consistency between business metrics and data models. This section analyzes the most relevant ones — **dbt**, **Cube.js**, and **LookML** — as well as the **custom semantic layer** designed for this project.

### **dbt (Data Build Tool)**

**Advantages:**

- Open-source and widely adopted in modern data stacks;
    
- Enables **centralized metric definitions** and **data documentation** directly in the warehouse;
    
- Ensures metric consistency across dashboards and analyses through SQL-based models;
    
- Integrates well with pipelines for transformation and data validation.
    

**Limitations:**

- Primarily focused on **data transformation**, not on real-time visualization or interactive APIs;
    
- Requires a pre-existing **SQL infrastructure** and data warehouse;
    
- Less suitable for **on-demand semantic querying** in real-time scenarios.
    

**Fit to the project:**  
While dbt provides robust semantic consistency and governance, its batch-oriented nature makes it less suited for **real-time NL→Dash generation**, where the mapping must occur dynamically in response to user prompts. However, it establishes a strong conceptual foundation for **metric lineage** and **definition versioning**, which can inspire the project’s semantic layer.

---

### **Cube.js**

**Advantages:**

- Offers a powerful **semantic API layer** that abstracts complex queries into reusable metrics and dimensions;
    
- Supports **real-time streaming** and caching mechanisms, ideal for analytics dashboards;
    
- Provides flexible APIs compatible with multiple visualization front-ends;
    
- Facilitates **role-based data access** and fine-grained metric control.
    

**Limitations:**

- More complex to scale due to its **Node.js-based backend** and caching dependencies;
    
- Requires careful configuration to maintain low latency under high load;
    
- Steeper learning curve for teams unfamiliar with its API-driven model.
    

**Fit to the project:**  
Cube.js aligns closely with the **real-time semantic layer requirements** of NL→Dash. Its semantic abstraction and ability to serve metrics via APIs make it a strong candidate for integration or conceptual reference, especially for **mapping natural language KPIs to structured metrics** dynamically.

---

### **LookML (Looker Modeling Language)**

**Advantages:**

- Mature and **enterprise-grade semantic modeling language** integrated into Looker (Google Cloud);
    
- Strong support for **metric standardization**, version control, and governance;
    
- Simplifies complex analytical logic through reusable metric definitions.
    

**Limitations:**

- Proprietary and **tightly coupled to Looker’s ecosystem**;
    
- Limited flexibility when used outside the Looker environment;
    
- Less suitable for open integration into custom pipelines or lightweight architectures.
    

**Fit to the project:**  
LookML demonstrates the power of a **declarative semantic layer**, where metrics and relationships are explicitly defined. However, its **vendor lock-in** and lack of open integration make it unsuitable for an open, backend-driven system like NL→Dash. Its conceptual model, however, provides valuable inspiration for structuring **metric catalogs** and ensuring **semantic reusability**.

---

### **Custom Semantic Layer (Project-Specific Approach)**

**Advantages:**

- Fully adaptable to the **Contact Center as a Service (CCaaS)** domain, aligning precisely with the project’s data and business logic;
    
- Lightweight and integrable into the backend architecture;
    
- Enables custom **rule-based mappings**, such as synonym detection and KPI disambiguation;
    
- Offers full control over **semantic validation**, **metric lineage**, and **feedback integration**.
    

**Limitations:**

- Requires manual design of the **semantic schema**, including metrics, hierarchies, and relationships;
    
- Increased initial development effort for defining rules, taxonomies, and mapping logic;
    
- Maintenance depends on continuous updates to the **KPI ontology** as business requirements evolve.
    

**Fit to the project:**  
A **custom semantic layer** represents the most suitable solution for the NL→Dash pipeline. It combines the transparency and flexibility of open-source approaches (as seen in dbt and Cube.js) with the domain-specific precision required for **real-time mapping of natural language to KPIs**. This component enables the system to generate **semantically aligned JSON configurations**, ensuring consistency across user prompts, dashboards, and underlying data.

---

## **Critical Synthesis**

The **Semantic Mapping** stage ensures that natural language inputs are accurately translated into meaningful, system-recognized metrics and dimensions. While existing tools such as **dbt**, **Cube.js**, and **LookML** provide solid frameworks for semantic consistency, they are either too heavy for real-time processing or limited by proprietary ecosystems.

For the NL→Dash project, a **custom semantic layer** offers the best balance between **adaptability**, **lightweight integration**, and **domain-specific accuracy**. By embedding semantic rules directly into the backend, the system achieves **“semantically aligned JSON”** structures that maintain coherence between user intent and data representation — a prerequisite for the subsequent **JSON Generation** and **Validation** stages.

This approach reinforces the project’s objective: to create an intelligent, real-time analytics system capable of transforming natural language prompts into complete, semantically consistent dashboards.


## custom semantic mapping example (é a que vou usar)
### 1) Ontologia + sinónimos (YAML/JSON)

{
  "title": "Queue Performance — Suporte (Últimas 2h)",
  "layout": "2x2",
  "widgets": [
    {
      "type": "timeseries",
      "metrics": ["aht", "wait_time_avg"],
      "dimensions": ["started_at"],
      "filters": [
        { "dimension": "queue", "operator": "=", "value": "Suporte" },
        { "dimension": "started_at", "operator": ">= ", "value": "now()-120m" }
      ]
    },
    {
      "type": "kpi",
      "metric": "aht",
      "filters": [
        { "dimension": "queue", "operator": "=", "value": "Suporte" },
        { "dimension": "started_at", "operator": ">= ", "value": "now()-120m" }
      ],
      "thresholds": { "good": "<=180", "warn": "<=240" }
    }
  ]
}


### 2) Resolução do pedido → JSON alinhado

{
  "title": "Queue Performance — Suporte (Últimas 2h)",
  "layout": "2x2",
  "widgets": [
    {
      "type": "timeseries",
      "metrics": ["aht", "wait_time_avg"],
      "dimensions": ["started_at"],
      "filters": [
        { "dimension": "queue", "operator": "=", "value": "Suporte" },
        { "dimension": "started_at", "operator": ">= ", "value": "now()-120m" }
      ]
    },
    {
      "type": "kpi",
      "metric": "aht",
      "filters": [
        { "dimension": "queue", "operator": "=", "value": "Suporte" },
        { "dimension": "started_at", "operator": ">= ", "value": "now()-120m" }
      ],
      "thresholds": { "good": "<=180", "warn": "<=240" }
    }
  ]
}


---
[[State of art]]

  

### ==verificar que abordagem devo de seguir==

# **Foundations and Related Technologies — Stage 2: Semantic Mapping**

  

## **Stage Introduction**

  

The second stage of the **NL→Dash** pipeline, **Semantic Mapping**, is responsible for translating the interpreted user intent into a structured and **semantically consistent representation of metrics, dimensions, and filters**. After the Prompt/Intent stage identifies the intent (e.g., _create dashboard for queue performance_), Semantic Mapping ensures that the terminology used by the user is **aligned with the system’s internal data model**.

  

This process guarantees that terms such as “average wait time” or “AHT” are mapped to the correct internal **Key Performance Indicators (KPIs)**, calculation logic, and database fields. The outcome of this phase is a **semantically aligned JSON structure**, ensuring that every metric and dimension referenced by the user corresponds to an actual data entity within the analytics warehouse.

  

Semantic Mapping thus plays a critical role in **bridging natural language and data semantics**, reducing ambiguity and maintaining the consistency of dashboards generated through language-driven interaction. In practical terms, it acts as a **semantic layer** that formalizes and validates metric definitions, providing a shared vocabulary across the NL→Dash pipeline.

  

---

  

## **Technological Analysis**

  

Several technologies and frameworks implement similar principles of semantic consistency between business metrics and data models. This section analyzes the most relevant ones — **dbt [1]–[4]**, **Cube [5]–[7].js**, and **LookML [8]–[10]** — as well as the **custom semantic layer** designed for this project.

  

### **dbt (Data Build Tool)**

  

**Advantages:**

  

- Open-source and widely adopted in modern data stacks;

- Enables **centralized metric definitions** and **data documentation** directly in the warehouse;

- Ensures metric consistency across dashboards and analyses through SQL-based models;

- Integrates well with pipelines for transformation and data validation.

  

**Limitations:**

  

- Primarily focused on **data transformation**, not on real-time visualization or interactive APIs;

- Requires a pre-existing **SQL infrastructure** and data warehouse;

- Less suitable for **on-demand semantic querying** in real-time scenarios.

  

**Fit to the project:**  

While dbt provides robust semantic consistency and governance, its batch-oriented nature makes it less suited for **real-time NL→Dash generation**, where the mapping must occur dynamically in response to user prompts. However, it establishes a strong conceptual foundation for **metric lineage** and **definition versioning**, which can inspire the project’s semantic layer.

  

---

  

### **Cube.js**

  

**Advantages:**

  

- Offers a powerful **semantic API layer** that abstracts complex queries into reusable metrics and dimensions;

- Supports **real-time streaming** and caching mechanisms, ideal for analytics dashboards;

- Provides flexible APIs compatible with multiple visualization front-ends;

- Facilitates **role-based data access** and fine-grained metric control.

  

**Limitations:**

  

- More complex to scale due to its **Node.js-based backend** and caching dependencies;

- Requires careful configuration to maintain low latency under high load;

- Steeper learning curve for teams unfamiliar with its API-driven model.

  

**Fit to the project:**  

Cube.js aligns closely with the **real-time semantic layer requirements** of NL→Dash. Its semantic abstraction and ability to serve metrics via APIs make it a strong candidate for integration or conceptual reference, especially for **mapping natural language KPIs to structured metrics** dynamically.

  

---

  

### **LookML (Looker Modeling Language)**

  

**Advantages:**

  

- Mature and **enterprise-grade semantic modeling language** integrated into Looker (Google Cloud);

- Strong support for **metric standardization**, version control, and governance;

- Simplifies complex analytical logic through reusable metric definitions.

  

**Limitations:**

  

- Proprietary and **tightly coupled to Looker’s ecosystem**;

- Limited flexibility when used outside the Looker environment;

- Less suitable for open integration into custom pipelines or lightweight architectures.

  

**Fit to the project:**  

LookML demonstrates the power of a **declarative semantic layer**, where metrics and relationships are explicitly defined. However, its **vendor lock-in** and lack of open integration make it unsuitable for an open, backend-driven system like NL→Dash. Its conceptual model, however, provides valuable inspiration for structuring **metric catalogs** and ensuring **semantic reusability**.

  

---

  

### **Custom Semantic Layer (Project-Specific Approach)**

  

**Advantages:**

  

- Fully adaptable to the **Contact Center as a Service (CCaaS)** domain, aligning precisely with the project’s data and business logic;

- Lightweight and integrable into the backend architecture;

- Enables custom **rule-based mappings**, such as synonym detection and KPI disambiguation;

- Offers full control over **semantic validation**, **metric lineage**, and **feedback integration**.

  

**Limitations:**

  

- Requires manual design of the **semantic schema**, including metrics, hierarchies, and relationships;

- Increased initial development effort for defining rules, taxonomies, and mapping logic;

- Maintenance depends on continuous updates to the **KPI ontology** as business requirements evolve.

  

**Fit to the project:**  

A **custom semantic layer** represents the most suitable solution for the NL→Dash pipeline. It combines the transparency and flexibility of open-source approaches (as seen in dbt and Cube.js) with the domain-specific precision required for **real-time mapping of natural language to KPIs**. This component enables the system to generate **semantically aligned JSON configurations**, ensuring consistency across user prompts, dashboards, and underlying data.

  

---

  

## **Critical Synthesis**

  

The **Semantic Mapping** stage ensures that natural language inputs are accurately translated into meaningful, system-recognized metrics and dimensions. While existing tools such as **dbt**, **Cube.js**, and **LookML** provide solid frameworks for semantic consistency, they are either too heavy for real-time processing or limited by proprietary ecosystems.

  

For the NL→Dash project, a **custom semantic layer** offers the best balance between **adaptability**, **lightweight integration**, and **domain-specific accuracy**. By embedding semantic rules directly into the backend, the system achieves **“semantically aligned JSON”** structures that maintain coherence between user intent and data representation — a prerequisite for the subsequent **JSON Generation** and **Validation** stages.

  

This approach reinforces the project’s objective: to create an intelligent, real-time analytics system capable of transforming natural language prompts into complete, semantically consistent dashboards.


### Referências

  

[1] dbt Labs, “dbt Semantic Layer,” 2025. https://docs.getdbt.com/docs/use-dbt-semantic-layer/dbt-sl

[2] dbt Labs, “About MetricFlow,” 2025. https://docs.getdbt.com/docs/build/about-metricflow

[3] dbt Labs, “MetricFlow commands,” 2025. https://docs.getdbt.com/docs/build/metricflow-commands

[4] dbt Labs, “Measures,” 2025. https://docs.getdbt.com/docs/build/measures

[5] Cube, “Getting started with data modeling,” 2025. https://cube.dev/docs/product/data-modeling/overview

[6] Cube, “Dynamic data models,” 2025. https://cube.dev/docs/product/data-modeling/dynamic

[7] Cube, “Generating the data model dynamically,” 2025. https://cube.dev/docs/product/data-modeling/recipes/using-dynamic-measures

[8] Google, “Introduction to LookML,” 2025. https://docs.cloud.google.com/looker/docs/what-is-lookml

[9] Google, “LookML reference overview,” 2025. https://cloud.google.com/looker/docs/reference/lookml-quick-reference

[10] Google, “Get ready for development (LookML),” 2025. https://docs.cloud.google.com/looker/docs/data-modeling

[11] A. Narechania et al., “NL4DV,” IEEE VIS 2020. https://faculty.cc.gatech.edu/~john.stasko/papers/infovis20-nl4dv.pdf

[12] T. Gao et al., “DataTone: Managing Ambiguity in NL Interfaces for Data Visualization,” UIST 2015. https://info290.github.io/papers/data-tone.pdf

[13] V. Setlur et al., “Eviza: A Natural Language Interface for Visual Analysis,” UIST 2016. https://dl.acm.org/doi/10.1145/2984511.2984588

[14] Vega-Lite, “View Specification,” 2025. https://vega.github.io/vega-lite/docs/spec.html

[15] Vega, “Specification,” 2025. https://vega.github.io/vega/docs/specification/





---

# 3.3.2 Mapeamento Semântico — Introdução

O **Mapeamento Semântico** (Stage 2) é a ponte entre a intenção interpretada no Stage 1 e a **representação estruturada** que o sistema consegue executar. Partindo do **IntentEnvelope** (ação, alvo, parâmetros e janela temporal), este estágio **alinha a terminologia do utilizador com o modelo de dados interno**, resolvendo sinónimos e acrónimos (por exemplo, “tempo médio de espera” ≡ _wait_time_avg_, “AHT” ≡ _avg_handle_time_) e garantindo que **cada métrica, dimensão e filtro apontam para entidades reais** do _warehouse_ (IDs canónicos, fórmulas e unidades oficiais). O resultado é um **SemanticPlan** consistente — métricas normalizadas com unidade, dimensões com granularidade adequada e filtros tipados — que **elimina ambiguidades** e preserva o contexto do diálogo; este plano é então consumido pelo Stage 3, que o converte em **JSON válido para o renderer** (Title, Layout, Widgets, Métricas, Filtros e Limiares). Conceitualmente, esta camada alinha-se com abordagens de **camadas semânticas** utilizadas em ferramentas como **dbt** [1][2], **Cube** [6][7] e **LookML** [10][11].

---

# 3.3.2-A Análise Tecnológica (dbt, Cube.js, LookML, camada semântica custom)

## Objetivo

Comparar tecnologias que promovem **consistência semântica** entre linguagem natural, métricas de negócio e o modelo de dados, e justificar a opção por uma **camada semântica custom** no **NL→Dash** (tempo real, baixo acoplamento e domínio CCaaS).

### dbt (Core, Semantic Layer e MetricFlow)

O **dbt Core** é _open-source_ e centra-se na **transformação em SQL** com documentação e linhagem de modelos; serve bem como **fonte de verdade** para métricas e modelos no _warehouse_ [1]. A **dbt Semantic Layer**, **assente no MetricFlow**, **centraliza definições de métricas** e expõe-nas de forma consistente a ferramentas a jusante [2]; a arquitetura do ecossistema explica como a camada **gera SQL e _joins_** e disponibiliza interfaces de consulta [4]. O **MetricFlow** permite **definir e consultar métricas de forma declarativa**, automatizando queries dimensionadas e disponibilizando **comandos/SDKs** para integração [3][5]. **Enquadramento no projeto:** excelente para **governação, linhagem e versionamento** de métricas; menos indicado, por si só, para mapeamento semântico **em tempo real** orientado a conversação.

### Cube / Cube.js

O **Cube** posiciona-se como **camada semântica universal**, com **APIs** para servir métricas/dimensões e **mecanismos de _caching_ e pré-agregações** para acelerar dashboards [6]. Suporta **experiências _real-time_** via **REST + WebSocket** (subscrições) e documenta **casos de uso de real-time analytics** [7][8][9]. **Enquadramento no projeto:** muito alinhado com **servir métricas em baixa latência**; útil como **gateway semântico** ou referência arquitetural para o teu fluxo **SemanticPlan → JSON**.

### LookML (Looker)

O **LookML** é uma **linguagem declarativa de modelação semântica** que descreve **dimensões, medidas, agregações e relações** e gera SQL sobre a base de dados; a documentação cobre a introdução e a referência (model, explore, view, tipos de measures) [10][11]. **Enquadramento no projeto:** poderoso como **modelo conceptual** de padronização e reuso, mas **proprietário** e **acoplado ao ecossistema Looker**, o que limita a integração num backend aberto.

### Camada Semântica **Custom** (projeto)

Para o **NL→Dash**, uma camada **custom** oferece o melhor compromisso: **aderência total ao domínio CCaaS** (sinónimos, acrónimos, regras), **latência baixa** e **controlo** sobre validações, unidades, limiares e RBAC. Pode **importar catálogos** de dbt/Cube como fonte de verdade **sem _lock-in_**, e operar com abordagem **regra-primeiro + LLM assistido** (apenas em paráfrases raras, com _constrained decoding_) para manter **determinismo** e **previsibilidade** na produção do **SemanticPlan**.

**Síntese:** dbt, Cube e LookML trazem princípios fortes de **governação, padronização e reuso**; para **conversação em tempo real**, a **camada custom** dá **precisão de domínio**, **baixa latência** e **independência tecnológica**, mantendo o JSON final **alinhado semanticamente** com o _warehouse_ e com o renderer do NL→Dash.

---

## Referências

[1] dbt Docs — _What is dbt?_ (dbt Core, _open-source_, transformação em SQL).  
[2] dbt Docs — _dbt Semantic Layer (overview)_ (centralização de métricas; alimentada por MetricFlow).  
[3] dbt Docs — _About MetricFlow_ (definir/consultar métricas; geração de SQL dimensionado).  
[4] dbt Docs — _Semantic Layer architecture_ (gera SQL e _joins_; interfaces para consultar métricas).  
[5] dbt Docs — _MetricFlow commands_ (comandos/integrações para consulta de métricas).  
[6] Cube Docs — _Introduction_ (camada semântica universal; APIs e aceleração).  
[7] Cube Docs — _Real-Time data fetch in the REST API_ (**WebSocket** e **subscrições** para atualizações em tempo real).  
[8] Cube Docs — _REST API_ (entrega de dados por HTTP; casos de uso, incluindo **embedded** e **real-time**).  
[9] Cube Use-Case — _Real-time Analytics_ (query unificada a dados de streaming+batch).  
[10] Looker Docs — _Introduction to LookML_ (modelação semântica declarativa; dimensões, agregações, relações).  
[11] Looker Docs — _LookML reference overview_ (estrutura do projeto e _measure types_).


# **3.3.2 Mapeamento Semântico — Introdução**

O **Mapeamento Semântico** constitui a segunda etapa do pipeline **NL→Dash**, funcionando como **ponte entre a intenção linguística (Stage 1)** e a **representação estruturada executável (Stage 3)**. A partir do **IntentEnvelope** — que contém a ação, o alvo, os parâmetros e a janela temporal —, este estágio tem como objetivo **alinhar a terminologia expressa pelo utilizador com o modelo de dados interno**, resolvendo sinónimos, acrónimos e variantes linguísticas.

Exemplo: “tempo médio de espera” é mapeado para o identificador canónico `_wait_time_avg_`; “AHT” corresponde a `_avg_handle_time_`.  
Cada métrica, dimensão e filtro é assim associado a uma **entidade real e validada no _data warehouse_**, garantindo integridade semântica. O produto final deste estágio é um **SemanticPlan**: uma representação estruturada que descreve métricas, dimensões e filtros tipados, normalizados e compatíveis com o schema interno do sistema.

Esta função aproxima-se do conceito de **semantic layer**, amplamente explorado em sistemas de _Business Intelligence (BI)_, onde uma camada intermédia traduz conceitos de negócio em estruturas de dados operacionais [1][2]. Em soluções analíticas modernas (ex.: dbt Semantic Layer, Cube.js, LookML), esta camada assegura **governação, padronização e reuso** das métricas, reduzindo inconsistências entre aplicações a jusante. No contexto do **NL→Dash**, essa mesma lógica é aplicada de forma dinâmica e conversacional, em tempo real, com ênfase em **baixa latência** e **precisão de domínio (CCaaS)**.

---

# **3.3.2-A Análise Tecnológica (dbt, Cube.js, LookML, camada semântica custom)**

## **1. Enquadramento comparativo**

O mapeamento semântico pode ser implementado através de diferentes paradigmas arquiteturais. Para avaliar as opções disponíveis, foram consideradas quatro dimensões de comparação, diretamente alinhadas com os requisitos do NL→Dash:

1. **Expressividade semântica** — capacidade de representar métricas compostas, hierarquias e dependências entre entidades.
    
2. **Latência e suporte a tempo real** — adequação a pipelines dinâmicos e fluxos de dados contínuos.
    
3. **Extensibilidade e integração** — possibilidade de interligar com APIs e componentes LLM.
    
4. **Independência tecnológica** — grau de _lock-in_ face a fornecedores ou ecossistemas proprietários.
    

---

## **2. Tecnologias analisadas**

### **dbt (Core, Semantic Layer e MetricFlow)**

O **dbt Core** é uma ferramenta _open-source_ de transformação de dados orientada a SQL, amplamente usada para criar pipelines reproduzíveis e documentados. A sua extensão, a **dbt Semantic Layer**, baseada em **MetricFlow**, introduz um modelo de **definição centralizada de métricas** e um motor que as expõe a ferramentas analíticas externas [3][4].

O **MetricFlow** permite **declarar métricas e dimensões** de forma declarativa, gerando automaticamente _joins_ e _queries_ otimizadas [5]. A arquitetura é desenhada para **garantir coerência semântica e governação de dados**, sendo ideal para cenários onde a rastreabilidade e a consistência de métricas são prioritárias.

**Limitação:** o modelo é orientado a execução _batch_ e não foi concebido para **resolução semântica em tempo real** — tornando-o menos adequado a um pipeline conversacional que exige respostas sub-segundo.

---

### **Cube / Cube.js**

O **Cube.js** define-se como uma **camada semântica universal** que disponibiliza APIs (REST, GraphQL e WebSocket) para servir métricas, dimensões e agregações [6]. O sistema inclui mecanismos de **_caching_ inteligente e pré-agregações**, o que o torna eficaz em **contextos de baixa latência** e **análises em tempo real** [7][8].

O Cube suporta também **subscrições WebSocket** que permitem atualizações dinâmicas, alinhando-se bem com pipelines baseados em eventos e dashboards reativos [9].

**Enquadramento no projeto:** o Cube fornece um modelo **API-driven** e escalável que poderia servir como **gateway semântico** entre o SemanticPlan e o renderer do NL→Dash. Contudo, a sua configuração é mais voltada para entrega de dados pré-agregados do que para resolução semântica contextualizada a linguagem natural.

---

### **LookML (Looker)**

O **LookML** é uma **linguagem declarativa de modelação semântica** utilizada na plataforma Looker, que define **dimensões, medidas e relações** em ficheiros versionáveis [10]. A partir dessas definições, o Looker gera SQL automaticamente, mantendo **consistência entre relatórios e métricas reutilizáveis** [11].

**Limitação:** apesar de o LookML oferecer excelente abstração semântica e governação, é **proprietário e fortemente acoplado ao ecossistema Google Cloud**, o que o torna inadequado para um sistema modular e aberto como o NL→Dash.

---

### **Camada Semântica Custom (projeto NL→Dash)**

Dada a necessidade de **baixa latência**, **controlo total sobre sinónimos e acrónimos** e **integração direta com o IntentEnvelope**, o projeto NL→Dash adota uma **camada semântica custom**.

Esta camada segue um modelo **regra-primeiro + LLM assistido**, no qual o raciocínio do modelo é restrito a casos de ambiguidade não resolvidos por regras, através de **_constrained decoding_**. O sistema mantém um catálogo centralizado (métricas, unidades, limiares, RBAC) e pode **importar catálogos de dbt ou Cube** como fontes de verdade, sem gerar _lock-in_.

**Vantagens:**

- **Determinismo e previsibilidade** na geração do SemanticPlan;
    
- **Aderência total ao domínio CCaaS**;
    
- **Integração direta** com o modelo de diálogo;
    
- **Baixa latência**, adequada a _feedback loops_ em tempo real.
    

---

## **3. Comparação Sintetizada**

|Tecnologia|Paradigma|Tempo real|Lock-in|Expressividade|Adequação ao NL→Dash|
|---|---|---|---|---|---|
|**dbt + MetricFlow**|Declarativo (SQL/Metric Layer)|Baixo|Médio|Alta|Forte em governação e rastreabilidade; fraco em latência.|
|**Cube.js**|API-driven + _Caching_|Alto|Baixo|Média|Alinhado com tempo real; requer camada extra para interpretação semântica.|
|**LookML**|Declarativo (Looker)|Médio|Alto|Alta|Padronização elevada; integração limitada fora do ecossistema Google.|
|**Camada Custom**|Regra-primeiro + LLM assistido|Alto|Nulo|Alta|Ideal para contexto CCaaS e pipelines conversacionais em tempo real.|

---

## **4. Discussão e enquadramento**

A comparação revela **três paradigmas distintos**:

- o **declarativo**, centrado em governação e rastreabilidade (dbt, LookML);
    
- o **API-driven**, focado em performance e entrega de métricas em tempo real (Cube.js);
    
- e o **híbrido rule+LLM**, que o NL→Dash adota para equilibrar **determinismo, domínio e velocidade**.
    

Enquanto soluções declarativas asseguram consistência, elas impõem **latência e dependência de schema fixo**. Já abordagens API-driven reduzem tempo de resposta, mas carecem de mecanismos de **interpretação semântica contextual** — essenciais num pipeline conversacional. Assim, uma camada custom combina o **rigor estrutural do declarativo** com a **flexibilidade de resolução linguística do LLM**, garantindo **coesão semântica** sem comprometer a **responsividade**.


---

## **5. Síntese final**

As tecnologias analisadas partilham o objetivo de garantir **consistência semântica** entre métricas e dados, mas diferem no equilíbrio entre **governação, latência e flexibilidade**. O **dbt** e o **LookML** representam maturidade e rastreabilidade, o **Cube** destaca-se pela execução em tempo real, e a **camada custom** do NL→Dash surge como uma solução **híbrida e específica de domínio**, combinando **rigor declarativo** com **interpretação linguística controlada**.

Esta escolha garante **autonomia tecnológica**, **baixa latência** e **fidelidade semântica**, condições essenciais para que o **SemanticPlan** mantenha correspondência direta com o _data warehouse_ e com o renderer do sistema.

---

## **Referências**

[1] J. López et al., “Semantic Layers for Data Analytics: Bridging Business Logic and Data Warehouses,” _IEEE Transactions on Knowledge and Data Engineering_, vol. 35, no. 4, 2023.  
[2] S. Mohanty et al., “Design of Semantic Models in Business Intelligence Systems,” _Springer Journal of Data Analytics_, 2022.  
[3] dbt Docs — _What is dbt?_ (transformação em SQL e governação de métricas).  
[4] dbt Docs — _dbt Semantic Layer (overview)_ (centralização e exposição de métricas).  
[5] dbt Docs — _About MetricFlow_ (definição declarativa e queries automáticas).  
[6] Cube Docs — _Introduction_ (camada semântica universal; APIs e aceleração).  
[7] Cube Docs — _Real-Time data fetch in the REST API_ (subscrições WebSocket).  
[8] Cube Docs — _REST API_ (entrega de dados por HTTP e streaming).  
[9] Cube Use-Case — _Real-time Analytics_ (unificação streaming+batch).  
[10] Looker Docs — _Introduction to LookML_ (modelação declarativa).  
[11] Looker Docs — _LookML Reference Overview_ (estruturas e tipos de medidas).
