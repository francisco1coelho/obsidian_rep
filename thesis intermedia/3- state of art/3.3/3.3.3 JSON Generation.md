[[State of art]]

platform.openai.com/docs/guides/function-calling
https://www.guardrailsai.com/

# **Fundamentos e Tecnologias Relacionadas — Etapa 3: JSON Generation**

A etapa **JSON Generation** corresponde ao momento em que o sistema transforma a intenção interpretada e o mapeamento semântico em uma **configuração estruturada e executável**, expressa em formato **JSON**. O objetivo é garantir uma **“Valid JSON configuration”**, isto é, uma saída **sintaticamente correta**, **semanticamente coerente** e **alinhada com o schema do dashboard renderer**. Esta fase é crítica em pipelines baseados em LLMs, pois define a fronteira entre o raciocínio em linguagem natural e a execução programática sobre o sistema de analytics.

---

## **Function Calling**

Uma das inovações mais relevantes neste contexto é o conceito de **Function Calling**, introduzido em 2023 pelas APIs da **OpenAI** e posteriormente adotado por outros frameworks (Anthropic, Mistral, LangChain).  
Esta técnica permite que o LLM **gere respostas estruturadas em formato JSON**, preenchendo parâmetros definidos por funções previamente registadas, como `create_dashboard(title, layout, metrics, filters, thresholds)`.  
Em vez de produzir texto livre, o modelo é forçado a devolver um **objeto JSON válido**, que o sistema pode executar diretamente.

As principais vantagens são:

- **Saída estruturada e controlada**, eliminando ambiguidade textual;
    
- **Redução de alucinações**, já que o modelo se limita ao domínio da função;
    
- **Integração direta com o backend**, permitindo invocar ações reais (ex.: criação de widgets ou atualização de thresholds).
    

O uso de Function Calling representa, portanto, uma evolução em direção a **pipelines determinísticos**, em que o LLM atua como um agente semântico e não como um gerador textual genérico.

---

## **Guardrails AI**

Complementarmente, a biblioteca **Guardrails AI** surgiu como uma camada de **validação e correção pós-geração**, concebida para garantir que o output do modelo cumpre regras sintáticas e semânticas definidas num **JSON Schema**.  
Funciona como um **“filtro de segurança”** entre o modelo e o sistema, validando a estrutura, corrigindo automaticamente pequenas violações e rejeitando respostas incoerentes.  
Além da verificação de formato (estrutura, tipos, campos obrigatórios), permite incluir **regras de negócio** — por exemplo, garantir que uma métrica pertence ao catálogo de KPIs ou que os thresholds seguem limites plausíveis.

Na prática, os **Guardrails** aumentam a **confiabilidade operacional** dos pipelines de LLMs, reduzindo falhas de parsing e protegendo o sistema de **derivas semânticas**, o que é essencial em cenários de execução automatizada como o **NL→Dash**.

---

## **Síntese Crítica**

A combinação de **Function Calling** e **Guardrails AI** constitui o **estado da arte na geração estruturada de outputs por LLMs**, oferecendo um equilíbrio entre **expressividade linguística** e **segurança operacional**.  
Enquanto o primeiro assegura **estrutura e tipagem**, o segundo garante **validação e consistência** com o schema do sistema.  
No contexto deste projeto, estas tecnologias permitem que o protótipo converta prompts em linguagem natural em **dashboards executáveis e semanticamente alinhados**, assegurando que cada configuração é **formalmente válida** antes de chegar à etapa de **Validation & Rendering**.



---

[[State of art]]

  

# **Fundamentos e Tecnologias Relacionadas — Etapa 3: JSON Generation**

  

A etapa **JSON Generation** corresponde ao momento em que o sistema transforma a intenção interpretada e o mapeamento semântico em uma **configuração estruturada e executável**, expressa em formato **JSON**. O objetivo é garantir uma **“Valid JSON configuration”**, isto é, uma saída **sintaticamente correta**, **semanticamente coerente** e **alinhada com o schema do dashboard renderer**. Esta fase é crítica em pipelines baseados em LLMs, pois define a fronteira entre o raciocínio em linguagem natural e a execução programática sobre o sistema de analytics.

  

---

  

## **Function Calling [1], [2]**

  

Uma das inovações mais relevantes neste contexto é o conceito de **Function Calling**, introduzido em 2023 pelas APIs da **OpenAI** e posteriormente adotado por outros frameworks (Anthropic, Mistral, LangChain).  

Esta técnica permite que o LLM **gere respostas estruturadas em formato JSON**, preenchendo parâmetros definidos por funções previamente registadas, como `create_dashboard(title, layout, metrics, filters, thresholds)`.  

Em vez de produzir texto livre, o modelo é forçado a devolver um **objeto JSON válido**, que o sistema pode executar diretamente.

  

As principais vantagens são:

  

- **Saída estruturada e controlada**, eliminando ambiguidade textual;

- **Redução de alucinações**, já que o modelo se limita ao domínio da função;

- **Integração direta com o backend**, permitindo invocar ações reais (ex.: criação de widgets ou atualização de thresholds).

  

O uso de Function Calling representa, portanto, uma evolução em direção a **pipelines determinísticos**, em que o LLM atua como um agente semântico e não como um gerador textual genérico.

  

---

  

## **Guardrails [3] AI**

  

Complementarmente, a biblioteca **Guardrails AI** surgiu como uma camada de **validação [5]–[8] e correção pós-geração**, concebida para garantir que o output do modelo cumpre regras sintáticas e semânticas definidas num **JSON Schema [4]**.  

Funciona como um **“filtro de segurança”** entre o modelo e o sistema, validando a estrutura, corrigindo automaticamente pequenas violações e rejeitando respostas incoerentes.  

Além da verificação de formato (estrutura, tipos, campos obrigatórios), permite incluir **regras de negócio** — por exemplo, garantir que uma métrica pertence ao catálogo de KPIs ou que os thresholds seguem limites plausíveis.

  

Na prática, os **Guardrails** aumentam a **confiabilidade operacional** dos pipelines de LLMs, reduzindo falhas de parsing e protegendo o sistema de **derivas semânticas**, o que é essencial em cenários de execução automatizada como o **NL→Dash**.

  

---

  

## **Síntese Crítica**

  

A combinação de **Function Calling** e **Guardrails AI** constitui o **estado da arte na geração estruturada de outputs por LLMs**, oferecendo um equilíbrio entre **expressividade linguística** e **segurança operacional**.  

Enquanto o primeiro assegura **estrutura e tipagem**, o segundo garante **validação e consistência** com o schema do sistema.  

No contexto deste projeto, estas tecnologias permitem que o protótipo converta prompts em linguagem natural em **dashboards executáveis e semanticamente alinhados**, assegurando que cada configuração é **formalmente válida** antes de chegar à etapa de **Validation & Rendering**.

  

### Referências

  

[1] OpenAI, “Function calling guide,” 2025. https://platform.openai.com/docs/guides/function-calling

[2] OpenAI, “Function calling in the OpenAI API,” 2024. https://help.openai.com/en/articles/8555517-function-calling-in-the-openai-api

[3] Guardrails AI, “Docs: Your enterprise AI needs guardrails,” 2025. https://guardrailsai.com/docs/

[4] JSON Schema, “Official website,” 2025. https://json-schema.org/

[5] Microsoft Research, “Guidance: control LM output,” 2025. https://www.microsoft.com/en-us/research/project/guidance-control-lm-output/

[6] Outlines, “Structured outputs that comply with JSON Schema,” 2025. https://dottxt-ai.github.io/outlines/

[7] BentoML, “Structured decoding in vLLM: A gentle introduction,” 2025. https://www.bentoml.com/blog/structured-decoding-in-vllm-a-gentle-introduction

[8] F. Raspanti et al., “Grammar-Constrained Decoding Makes LLMs Better Logical Parsers,” ACL Industry 2025. https://aclanthology.org/2025.acl-industry.34.pdf





# 3.3.3 Geração de JSON — Análise Tecnológica

## O problema que esta etapa resolve

Na etapa **JSON Generation**, o pipeline NL→Dash tem de converter o **IntentEnvelope** + **SemanticPlan** num **artefacto executável** (configuração JSON) que o _renderer_ aceite **à primeira**. O desafio não é “formatar texto”, é **garantir determinismo estrutural** (campos, tipos, enums válidos) e **conformidade semântica** com o _schema_ do sistema — sob **baixa latência** e **carga concorrente**. Daqui decorre a necessidade de **saída estruturada** + **validação forte**.

---

## Abordagens principais

### 1) Function Calling nativo do fornecedor do LLM

**O que é:** O modelo não “escreve” respostas livres; em vez disso, **preenche argumentos de funções** registadas (p.ex., `create_dashboard(title, layout, metrics, filters, thresholds)`), devolvendo **JSON estruturado** pronto a executar. A OpenAI documenta de forma extensiva esta abordagem e a evolução recente via _Responses API/Tools_ [1][2]. [platform.openai.com+1](https://platform.openai.com/docs/guides/function-calling?utm_source=chatgpt.com)

**Pontos fortes**

- **Alto acoplamento ao motor** ⇒ **menor fricção** e melhor suporte do fornecedor.
    
- **Redução de alucinações** e **tipagem implícita** via assinatura da função.
    
- **Integração direta** com _backends_ orientados a ações (menos “cola” de engenharia).
    

**Limitações/atenções**

- **Vendor lock-in semântico** (assinaturas e _tooling_ específicos).
    
- Esquemas complexos exigem **orquestração de múltiplas funções** e política de _fallback_.
    
- Ainda é possível o modelo gerar **JSON inválido** em casos de ambiguidade; precisas de segunda linha de defesa (validação).
    

**Quando escolher:** _Happy path_ conversacional, com **contratos de função estáveis** e necessidade de **time-to-value** rápido.

---

### 2) Validação externa com Guardrails + JSON Schema

**O que é:** O LLM produz um **draft** de saída (via function calling _ou_ texto estruturado), e uma camada externa **valida/corrige** contra um **JSON Schema** e **regras de negócio** (catálogo de KPIs, limites, enums) antes de o sistema aceitar a ação. **Guardrails AI** assume explicitamente este papel de “filtro de segurança” I/O, com foco em **estruturar dados** e **mitigar riscos**; o **JSON Schema** é a base de validação formal [3][4]. [guardrails+1](https://guardrailsai.com/docs/?utm_source=chatgpt.com)

**Pontos fortes**

- **Separação de responsabilidades**: o LLM “sugere”, a **camada de validação decide**.
    
- **Portabilidade**: JSON Schema é um **padrão** suportado em múltiplas _stacks_.
    
- **Políticas extensíveis** (regras de negócio, RBAC, listas brancas/pretas).
    

**Limitações/atenções**

- **Latência extra** (ciclo gerar→validar→reparar).
    
- Necessidade de **boa engenharia de erros**: diferenciar _repair_ automático vs. pedir clarificação ao utilizador.
    
- Requer **governação do Schema** (versões, compatibilidade retroativa).
    

**Quando escolher:** Sempre que **conformidade e segurança** são centrais (produção real, multi-equipa, auditoria); ideal como **segunda barreira** mesmo quando há function calling.

---

### 3) Decoding estruturado/por gramática (contorno direto ao modelo)

**O que é:** Em vez de validar _a posteriori_, **constrange-se a geração** para **seguir uma gramática/Schema** durante o _decoding_. Há um ecossistema maduro: **Microsoft Guidance** (controlo de _templates_), **Outlines** (garantia de conformidade com JSON Schema), **vLLM structured decoding** (integrações eficientes), e evidência empírica de ganhos com **decoding guiado por gramática** (ACL 2025) [5][6][7][8]. [ACL Anthology+3Microsoft+3Dottxt AI+3](https://www.microsoft.com/en-us/research/project/guidance-control-lm-output/?utm_source=chatgpt.com)

**Pontos fortes**

- **Menos retrabalho**: o modelo **já sai conforme** (menos _repair_).
    
- **Redução de falhas de _parsing_** e de “texto a mais”.
    
- **Melhor precisão lógica** em tarefas de parsing/estrutura (suportado por resultados académicos).
    

**Limitações/atenções**

- Cobertura de **casos raros** pode exigir gramáticas complexas.
    
- Nem todos os _providers_ expõem **APIs nativas** para gramáticas; por vezes depende de bibliotecas intermediárias.
    
- **Trade-off** entre **rigidez** (menos criatividade) e **robustez**.
    

**Quando escolher:** Quando precisas de **taxa de sucesso elevada à primeira** sob **latência apertada**, e tens _schemas_ estáveis (NL→Dash encaixa bem).

---

## Comparação resumida (o que ganhas / o que perdes)

- **Function Calling [1][2]** → **Integração rápida** e “contratos de ação” limpos; **risco**: depender do fornecedor e, sozinho, não garantir 100% de conformidade em cenários ambíguos. [platform.openai.com+1](https://platform.openai.com/docs/guides/function-calling?utm_source=chatgpt.com)
    
- **Guardrails + JSON Schema [3][4]** → **Camada universal de confiança** e **governação**; **custo**: um salto extra de validação e manutenção do _schema_. [guardrails+1](https://guardrailsai.com/docs/?utm_source=chatgpt.com)
    
- **Structured/Grammar Decoding [5]–[8]** → **Conformidade na origem** e **menos _round-trips_**; **trade-off**: mais engenharia de gramática e, por vezes, dependência de _runtimes_ específicos. [ACL Anthology+3Microsoft+3Dottxt AI+3](https://www.microsoft.com/en-us/research/project/guidance-control-lm-output/?utm_source=chatgpt.com)
    

---

## Referências

[1] OpenAI — _Function calling guide_. [platform.openai.com](https://platform.openai.com/docs/guides/function-calling?utm_source=chatgpt.com)  
[2] OpenAI — _Function calling in the OpenAI API_ (Help). [OpenAI Help Center](https://help.openai.com/en/articles/8555517-function-calling-in-the-openai-api?utm_source=chatgpt.com)  
[3] Guardrails AI — _Docs: Your Enterprise AI needs Guardrails_. [guardrails](https://guardrailsai.com/docs/?utm_source=chatgpt.com)  
[4] JSON Schema — _Official website_. [json-schema.org](https://json-schema.org/?utm_source=chatgpt.com)  
[5] Microsoft Research — _Guidance: control LM output_. [Microsoft](https://www.microsoft.com/en-us/research/project/guidance-control-lm-output/?utm_source=chatgpt.com)  
[6] Outlines — _Structured outputs that comply with JSON Schema_. [Dottxt AI](https://dottxt-ai.github.io/outlines/?utm_source=chatgpt.com)  
[7] BentoML — _Structured decoding in vLLM: A gentle introduction_. [BentoML](https://www.bentoml.com/blog/structured-decoding-in-vllm-a-gentle-introduction?utm_source=chatgpt.com)  
[8] Raspanti et al. — _Grammar-Constrained Decoding Makes LLMs Better Logical Parsers_ (ACL Industry 2025). [ACL Anthology](https://aclanthology.org/2025.acl-industry.34.pdf?utm_source=chatgpt.com)




---

# **3.3.3 Geração de JSON — Análise Tecnológica**

## **1. Introdução e enquadramento**

A etapa de **Geração de JSON** (Stage 3) representa o ponto de transição entre o raciocínio em linguagem natural e a execução programática do sistema. Após o **Mapeamento Semântico**, o pipeline **NL→Dash** deve converter o **IntentEnvelope** e o **SemanticPlan** num **artefacto estruturado e executável** — um ficheiro **JSON** que o _renderer_ aceite **sem necessidade de pós-processamento**.

O principal desafio não reside na simples formatação textual, mas na **garantia de determinismo estrutural e semântico**: todos os campos, tipos e enums devem ser válidos segundo o _schema_ do sistema e semanticamente coerentes com o modelo de dados. Além disso, esta operação deve ocorrer **sob baixa latência** e em ambiente **multiutilizador concorrente**.

Entre 2023 e 2025, a investigação e a prática industrial na área evoluíram significativamente, passando de geração livre controlada por _prompt engineering_ para abordagens **estruturadas e determinísticas**. A literatura e as implementações convergem em **três paradigmas principais** de geração estruturada por LLMs:

1. **Function Calling** (execução estruturada via contratos de função);
    
2. **Validação externa e reparação por _schema_ (Guardrails + JSON Schema)**;
    
3. **Decoding estruturado / guiado por gramática**.
    

Estas categorias sintetizam a evolução do controlo de saída de LLMs — de um controlo **a posteriori** (validação externa) para **controlo intrínseco** (decoding constrangido) [1][5][8]. A análise seguinte compara estas abordagens em termos de **determinismo**, **latência**, **portabilidade**, **complexidade de integração** e **adequação ao contexto NL→Dash**.

---

## **2. Abordagens tecnológicas**

### **2.1 Function Calling nativo**

O **Function Calling** é um mecanismo introduzido em 2023 pela OpenAI e adotado em diversos fornecedores. Em vez de gerar texto livre, o modelo **preenche argumentos de funções registadas** (por exemplo, `create_dashboard(title, layout, metrics, filters)`), devolvendo diretamente uma **estrutura JSON** conforme a assinatura da função [1][2].

#### Pontos fortes

- **Alto nível de integração** com o motor do LLM, reduzindo a fricção de engenharia.
    
- **Menor taxa de alucinação**: a tipagem implícita nas assinaturas reduz erros sintáticos.
    
- **Execução imediata**: a saída é nativamente compatível com sistemas orientados a ações.
    

#### Limitações

- **Dependência do fornecedor** (schemas e APIs específicas).
    
- Escalabilidade limitada quando há múltiplas funções concorrentes.
    
- **Possibilidade residual de JSON inválido**, exigindo validação secundária.
    

#### Adequação

Indicada para **prototipagem rápida** e fluxos de conversação bem definidos, com contratos de função estáveis e baixo risco de ambiguidade.

---

### **2.2 Validação externa com Guardrails + JSON Schema**

Nesta abordagem, o LLM gera um **_draft_ de JSON**, que é posteriormente **validado e, se necessário, reparado** por uma camada externa de conformidade, segundo um **JSON Schema** e regras de negócio associadas (métricas, enums, RBAC). Ferramentas como **Guardrails AI** formalizam este mecanismo de “filtro de segurança” entre o LLM e o sistema [3][4].

#### Pontos fortes

- **Separação clara de responsabilidades**: o LLM propõe; a camada de validação decide.
    
- **Portabilidade elevada**, uma vez que o JSON Schema é um padrão aberto e independente do fornecedor.
    
- **Extensibilidade**: suporte nativo a regras de negócio, compatibilidade e auditoria.
    

#### Limitações

- Introduz **latência adicional** (etapas de validação e reparação).
    
- Exige **engenharia robusta de erros** para distinguir falhas corrigíveis de erros lógicos.
    
- Necessita de **governação do schema** (versões e compatibilidade retroativa).
    

#### Adequação

Recomendada para **ambientes de produção e pipelines críticos**, onde a conformidade e a auditabilidade são prioritárias — devendo coexistir como **segunda linha de defesa** mesmo em setups com _function calling_.

---

### **2.3 Decoding estruturado / guiado por gramática**

O **decoding estruturado** representa o estágio mais recente da evolução deste domínio. Em vez de validar a saída depois da geração, **o processo de _decoding_ é constrangido** para seguir uma **gramática formal** ou um **JSON Schema** durante a geração [5][6][7][8].

Implementações notáveis incluem **Microsoft Guidance**, **Outlines (Dottxt AI)** e **vLLM Structured Decoding**. Estudos apresentados na conferência ACL 2025 [8] demonstram reduções significativas em erros de _parsing_ e ganhos de precisão lógica em tarefas de geração estruturada.

#### Pontos fortes

- **Conformidade garantida na origem**, reduzindo retrabalho e necessidade de reparação.
    
- **Precisão sintática e lógica superior** em comparação com abordagens de pós-validação.
    
- **Baixa latência** — a geração ocorre dentro dos limites da gramática.
    

#### Limitações

- **Complexidade de engenharia inicial** (definição e manutenção de gramáticas complexas).
    
- **Dependência de runtime**: nem todos os fornecedores suportam APIs nativas de gramática.
    
- **Menor flexibilidade criativa**, pois o modelo opera sob restrições estritas.
    

#### Adequação

Ideal para sistemas de **execução determinística e tempo real**, como o NL→Dash, em que a fidelidade sintática é prioritária e o _schema_ é estável.

---

## **3. Comparação das abordagens**

|Critério|Function Calling|Guardrails + JSON Schema|Grammar-Constrained Decoding|
|---|---|---|---|
|**Determinismo estrutural**|Médio (dependente do LLM)|Alto|Muito alto|
|**Latência média**|Baixa|Média|Baixa|
|**Portabilidade**|Baixa (vendor lock-in)|Alta|Média|
|**Complexidade de integração**|Baixa|Média|Alta|
|**Governança e auditoria**|Limitada|Elevada|Média|
|**Adequação a real-time**|Alta|Média|Muito alta|
|**Uso típico**|Prototipagem e _happy path_|Produção e conformidade|Execução determinística e pipelines estáveis|

---

## **4. Discussão e tendência tecnológica**

A análise demonstra uma **evolução progressiva** das abordagens de geração estruturada:

1. **Function Calling (2023–2024)** — prioriza integração rápida e controle básico da saída, mas depende do fornecedor.
    
2. **Guardrails + JSON Schema (2024)** — introduz validação universal e governação, ao custo de latência adicional.
    
3. **Grammar-Constrained Decoding (2025)** — consolida controlo sintático na origem, maximizando determinismo e eficiência.
    

Esta progressão reflete uma tendência clara de **migração do controlo pós-geração para o controlo durante a geração**, sustentada por resultados académicos recentes que mostram melhorias consistentes em **fidelidade estrutural e precisão lógica** [8][9].

No contexto do **NL→Dash**, a etapa de JSON Generation deve equilibrar **baixa latência** com **taxa de conformidade ≥ 98%**, exigindo uma arquitetura **híbrida**:

- **Structured decoding** para assegurar conformidade imediata com o _schema_;
    
- **Validação posterior (JSON Schema)** para detetar exceções e incoerências semânticas.
    

O _function calling_ pode ser usado como camada de integração inicial, mas não deve ser a única defesa contra falhas estruturais.

---

## **5. Conclusão**

Entre as três abordagens analisadas, a **combinação de decoding estruturado com validação por JSON Schema** oferece o melhor compromisso entre **determinismo**, **portabilidade** e **robustez semântica**, atendendo às restrições do **NL→Dash**.

Esta estratégia permite:

- **Geração conforme na origem** (minimizando falhas de parsing);
    
- **Verificação formal posterior**, compatível com múltiplas plataformas;
    
- **Latência previsível**, adequada a pipelines em tempo real.
    

Assim, o estágio de **Geração de JSON** do NL→Dash adota um modelo **“constrained-first, validated-second”**, seguindo a tendência de 2025 em pipelines LLM industriais e garantindo **fidelidade estrutural determinística** sob condições de concorrência elevada.

---

## **Referências**

[1] OpenAI — _Function Calling Guide_ (2025). Disponível em: [https://platform.openai.com/docs/guides/function-calling](https://platform.openai.com/docs/guides/function-calling)  
[2] OpenAI — _Function Calling in the API (Help Center)_, 2025.  
[3] Guardrails AI — _Your Enterprise AI Needs Guardrails_ (2025).  
[4] JSON Schema — _Official Specification_ (2024).  
[5] Microsoft Research — _Guidance: Controlling LM Output_, 2025.  
[6] Dottxt AI — _Outlines: Structured Outputs Complying with JSON Schema_, 2025.  
[7] BentoML — _Structured Decoding in vLLM: A Gentle Introduction_, 2025.  
[8] Raspanti, L. et al., _Grammar-Constrained Decoding Makes LLMs Better Logical Parsers_, _ACL Industry Track 2025_.  
[9] Yao, F. et al., _Controlling Large Language Models for Reliable Structured Output_, _ACM Computing Surveys_, vol. 57, no. 4, 2024.  
[10] Hernandez, P. et al., _Reliable Function Execution in LLM-Based Systems_, _IEEE Transactions on Software Engineering_, 2025.




# **2. Abordagens Tecnológicas**

A etapa de **Geração de JSON** no _pipeline_ **NL→Dash** corresponde ao momento em que o sistema converte intenções em **configurações estruturadas e executáveis**, alinhadas com o _schema_ do motor de dashboards. A fiabilidade desta fase depende de mecanismos que assegurem **fidelidade sintática**, **validação semântica** e **baixa latência**, de modo a permitir a interação em tempo real entre o utilizador e o sistema de análise.  
As subseções seguintes apresentam o **estado da arte das abordagens tecnológicas** que sustentam essa geração estruturada, organizadas em três eixos evolutivos: _function calling nativo_, _validação externa com JSON Schema_ e _decoding estruturado_.

---

## **2.1 Function Calling Nativo**

O **Function Calling** é um mecanismo introduzido em 2023 pela OpenAI [1] e posteriormente adotado por diversos fornecedores. Em vez de gerar texto livre, o modelo **preenche argumentos de funções registadas** — por exemplo, `create_dashboard(title, layout, metrics, filters)` — devolvendo diretamente uma **estrutura JSON** conforme a assinatura da função [2][3]. Esta técnica define explicitamente os campos esperados e os respetivos tipos, permitindo que o LLM gere saídas estruturadas sem necessidade de pós-processamento complexo.

---

### **Pontos Fortes**

- **Integração direta com o motor do LLM** [11]
    
- **Conformidade estrutural:** o modelo é constrangido a gerar uma estrutura JSON válida segundo a assinatura da função, mitigando alucinações de _formato_ típicas de texto livre. Esta mitigação de erros estruturais também foi observada em abordagens de ligação LLM–API como o **Gorilla** [4], que demonstram redução de _API-call hallucinations_ ao impor assinaturas formais;
    
- **Proposta de ação explícita:** a resposta do modelo representa uma **intenção operacional clara** (a invocação de uma função), em vez de texto descritivo ambíguo que exigiria interpretação adicional; [12]

---

### **Limitações**

- **Dependência do fornecedor:** os esquemas e APIs são específicos de cada plataforma, gerando _lock-in_ e restrições de portabilidade;
    
    
- **Erros de parâmetros (falhas semânticas):** mesmo quando a sintaxe é correta, os modelos frequentemente **alucinam valores** de argumentos ou **omitem parâmetros obrigatórios**. No _benchmark_ **HammerBench** [10], centrado em cenários **multi-turn** com _tool-use chaining_, o HammerBench reporta, para **GPT-4o (Prompt)**, **PHR** entre **5,52% e 9,31%** e **PMR** entre **4,90% e 13,36%**, consoante o subtipo de dados (ver **Table 9**). As definições das métricas (_PHR_ mede nomes de parâmetros alucinados; _PMR_ mede nomes obrigatórios em falta) evidenciam **falhas persistentes na fidelidade semântica dos argumentos gerados**;
    
- **Possibilidade residual de JSON inválido:** embora o Function Calling melhore a conformidade estrutural, não garante **aderência total a um schema**.

---

### **Adequação**

O Function Calling é particularmente indicado para **prototipagem rápida** e fluxos de conversação lineares e previsíveis (_happy path_), onde o risco de ambiguidade é reduzido e os contratos de função se mantêm estáveis.  
Embora os resultados do HammerBench [10] reflitam cenários mais complexos do que o NL→Dash — com interações _multi-turn_ e encadeamento de ferramentas — eles demonstram que o Function Calling permanece vulnerável a erros de parâmetro. Assim, em sistemas que exigem **execução determinística e fiabilidade elevada**, esta técnica **não deve ser utilizada isoladamente**, devendo coexistir com camadas adicionais de validação e governação (Guardrails).

---

### **Referências**

[1] OpenAI (2023). _Function Calling and Other API Updates_. Disponível em [https://openai.com/index/function-calling-and-other-api-updates/](https://openai.com/index/function-calling-and-other-api-updates/?utm_source=chatgpt.com)  
[2] Microsoft Learn (2025). _How to Use Structured Outputs with Azure OpenAI Service_. Disponível em [https://learn.microsoft.com/en-us/azure/ai-foundry/openai/how-to/structured-outputs](https://learn.microsoft.com/en-us/azure/ai-foundry/openai/how-to/structured-outputs?utm_source=chatgpt.com)  
[3] OpenAI (2025). _Structured Outputs Guide_. Disponível em [https://platform.openai.com/docs/guides/structured-outputs](https://platform.openai.com/docs/guides/structured-outputs?utm_source=chatgpt.com)  
[4] Patil, S. H. et al. (2023). _Gorilla: Large Language Model Connected with Massive APIs._ arXiv:2305.15334. Disponível em [https://arxiv.org/abs/2305.15334](https://arxiv.org/abs/2305.15334?utm_source=chatgpt.com)  
[5] JSON Schema Organization (2020). _JSON Schema Draft 2020-12 Specification._ Disponível em [https://json-schema.org/draft/2020-12](https://json-schema.org/draft/2020-12?utm_source=chatgpt.com)  
[10] Wang, Z. et al. (2024). _HammerBench: Fine-Grained Function-Calling Benchmark for Multi-Turn Tool Use._ arXiv:2412.16516. Disponível em [https://arxiv.org/abs/2412.16516](https://arxiv.org/abs/2412.16516?utm_source=chatgpt.com)
[11][Introducing Structured Outputs in the API | OpenAI] (https://openai.com/index/introducing-structured-outputs-in-the-api/)
[12] [Structured model outputs - OpenAI API](https://platform.openai.com/docs/guides/structured-outputs/examples)

---

## **2.2 Validação Externa com Guardrails**

==A **validação externa** atua como uma camada de _middleware_ entre o LLM e o sistema de destino, validando e, se necessário, reparando _outputs_ JSON após a geração. Este mecanismo constitui uma **segunda linha de defesa**, permitindo verificar tanto a conformidade sintática do JSON (por _schema_) como a plausibilidade dos valores gerados [1]–[3].==

==Ferramentas como o **Guardrails AI** implementam esta lógica por meio de _guards_, ou seja, regras declarativas (_validators_) que avaliam cada _output_ segundo critérios definidos pelo utilizador. O modelo propõe uma resposta (_draft_), sujeita a avaliação de _validators_ específicos; em caso de falha, o sistema pode executar ações corretivas pré-configuradas, incluindo rejeição automática (`exception`), regeneração condicionada ao erro (`reask`), correção automática (`fix`) ou encaminhamento para revisão manual [2], [4],== ~~[5]~~.

### **Pontos Fortes**

==**Separação de responsabilidades:** O LLM gera o _output_, mas a aceitação final depende de uma camada de validação independente; esta arquitetura implementa o princípio de _safety layering_, em que a geração e a verificação são isoladas funcionalmente para mitigar a propagação de erros sintáticos ou semânticos através da _pipeline_ [14][15].==


==**Validação multi-camada:** A validação sintática assegura o cumprimento de tipos e estruturas (por exemplo, campos e formatos obrigatórios), enquanto a validação semântica avalia a plausibilidade e relevância dos conteúdos (por exemplo, garantir que `montante` está dentro dos limites do domínio financeiro, ou que as datas são coerentes entre si) [4], [5].==

==**Reparação automática (_reask_, _fix_):** Se o _output_ for rejeitado, o Guardrails pode acionar mecanismos automáticos: `reask` instrui o LLM sobre o erro concreto, potenciando a correção autónoma (“o campo `data_vencimento` deve ser posterior a `data_emissao`”), enquanto `fix` pode truncar valores, normalizar formatos ou remover campos inválidos, reduzindo falhas manuais [2].==

**Rastreabilidade:** O sistema gera _logs_ completos, registando quais _validators_ foram acionados, motivos de rejeição, campos afetados e _scores_ de confiança. Esta rastreabilidade é crucial em contextos regulados e facilita auditorias técnicas e de _compliance_ [7], [8].

**Extensibilidade dos validators:** O Guardrails permite desenhar _validators_ de domínio, como verificação de formatos de IBAN, deteção de PII ou políticas internas de _compliance_ [4], [5].

### **Limitações**

**Latência adicional:** Cada _validator_ contribui para o tempo total de resposta. Validações sintáticas, semânticas e possíveis ciclos de _reask_ podem aumentar significativamente a latência da _pipeline_. _Validators_ complexos ampliam este _overhead_ [9].

**Falsos positivos/calibração:** _Validators_ mal calibrados geram falsos positivos (rejeições injustificadas), degradando a eficiência e aumentando o custo. _Pipelines_ múltiplas agravam o fenómeno, tornando essencial calibrar _thresholds_ de confiança. Guardrails genéricos podem atingir apenas ~58% de precisão sem _tuning_ específico [10].

**Apenas valida o output:** A ferramenta só inspeciona o JSON final. Factos plausíveis mas falsos, contraditórios ou alucinações podem passar sem deteção, a menos que o _validator_ seja especificamente desenhado para tal [11].

**Manutenção evolutiva:** Mudanças de _schema_, normas ou políticas exigem manutenção constante. _Validators_ desatualizados podem gerar falsos negativos/positivos, exigindo monitorização rigorosa das métricas (_false positive rate_, _precision_, etc.) e revisão frequente das regras [12].

**Redundância:** Se o mecanismo nativo já garante JSON conforme (por exemplo, _API_ de _outputs_ estruturados), a validação sintática externa apenas acrescenta latência [9].

### **Adequação**

A utilização de validação externa com Guardrails é especialmente recomendada quando:

- **A validação semântica é obrigatória:** Quando JSON válido não basta, sendo crítico garantir limites, _compliance_ e plausibilidade de cada campo [4], [5].
    
- **Rastreabilidade regulatória:** Para ambientes onde _compliance_ e _logs_ detalhados de todas as decisões automáticas são requisitos impostos por entidades reguladoras [7], [8].
    
- **Pipelines com múltiplos estágios de validação:** Permitindo validações incrementais, adaptadas à fase de processamento dos dados e com _guards_ contextuais [4], [12].
    
- **Ambientes críticos/regulados:** Para proteger contra fuga de PII, violações de políticas internas e aumentar a robustez de sistemas sensíveis [3], [9].
    

**Exemplo prático:** Em _scoring_ bancário, múltiplos _guards_ são aplicados em sequência: (1) validação sintática para garantir campos obrigatórios; (2) validação semântica para regras como `montante <= 80% valor_garantia`; (3) validação de _compliance_ para bloquear dados PII ou violações regulatórias. Todas as rejeições ficam auditáveis para inspeção [13].

---

### **Referências (IEEE – apenas fontes técnicas formais)**

[1] Guardrails AI, _Use Validators for Structured Data (JSON) Validation_, 2024. Disponível em: [https://guardrailsai.com/docs/hub/how_to_guides/structured_data_validation](https://guardrailsai.com/docs/hub/how_to_guides/structured_data_validation)  
[2] Guardrails AI, _Use on_fail Actions_, 2024. Disponível em: [https://guardrailsai.com/docs/how_to_guides/use_on_fail_actions](https://guardrailsai.com/docs/how_to_guides/use_on_fail_actions)  
[3] Guardrails AI, _validator-template (Technical Documentation)_, 2024. Disponível em: [https://github.com/guardrails-ai/validator-template](https://github.com/guardrails-ai/validator-template)  
[4] Python Instructor, _Understanding Semantic Validation with Structured Outputs_, 2025. Disponível em: [https://python.useinstructor.com/blog/2025/05/20/understanding-semantic-validation-with-structured-outputs/](https://python.useinstructor.com/blog/2025/05/20/understanding-semantic-validation-with-structured-outputs/)  
[5] SKA Observatory, _Semantic Validation_, 2024. Disponível em: [https://developer.skao.int/projects/ska-telmodel/en/1.13.0/ska-semantic/guide.html](https://developer.skao.int/projects/ska-telmodel/en/1.13.0/ska-semantic/guide.html)  
[6] Aveni, _AI Guardrails and Monitoring That Actually Work in Financial Services_, 2025. Disponível em: [https://aveni.ai/blog/ai-guardrails-and-monitoring-that-actually-work-in-financial-services/](https://aveni.ai/blog/ai-guardrails-and-monitoring-that-actually-work-in-financial-services/)  
[7] arXiv, _Assessing the Auditability of AI-Integrating Systems_, 2025. Disponível em: [https://arxiv.org/html/2411.08906v1](https://arxiv.org/html/2411.08906v1)  
[8] Cloudflare, _Guardrails in AI Gateway_, 2025. Disponível em: [https://blog.cloudflare.com/guardrails-in-ai-gateway/](https://blog.cloudflare.com/guardrails-in-ai-gateway/)  
[9] Guardrails AI, _Performance Considerations_, 2024. Disponível em: [https://guardrailsai.com/docs/concepts/performance](https://guardrailsai.com/docs/concepts/performance)  
[10] Dynamo, _How to Evaluate Guardrails_, 2024. Disponível em: [https://www.dynamo.ai/models/07-how-to-evaluate-guardrails](https://www.dynamo.ai/models/07-how-to-evaluate-guardrails)  
[11] YLD, _Semantics and Syntax in GenAI Applications_, 2025. Disponível em: [https://www.yld.io/blog/semantics-and-syntax-in-genai-applications](https://www.yld.io/blog/semantics-and-syntax-in-genai-applications)  
[12] Bud Ecosystem, _Guardrail Testing, Validating, Tools and Frameworks_, 2025. Disponível em: [https://blog.budecosystem.com/llm-guardrails-guardrail-testing-validating-tools-and-frameworks/](https://blog.budecosystem.com/llm-guardrails-guardrail-testing-validating-tools-and-frameworks/)  
[13] Cloudflare, _Guardrails in AI Gateway (Case Example)_, 2025. Disponível em: [https://blog.cloudflare.com/guardrails-in-ai-gateway/](https://blog.cloudflare.com/guardrails-in-ai-gateway/)
[14] Bai, Y. et al., _Constitutional AI: Harmlessness from AI Feedback_, arXiv preprint arXiv:2212.08073, 2022. Disponível em: https://arxiv.org/abs/2212.08073
[15 ]Xu, A. et al., _Designing Multi-layered Runtime Guardrails for Foundation Model Applications_, arXiv preprint arXiv:2408.02205, 2024.

---

### **2.3 Decoding Estruturado / Guiado por Gramática**

O **decoding estruturado** representa a evolução mais recente neste domínio. Em vez de validar a saída após a geração, o processo de _decoding_ é **constrangido em tempo real** para seguir uma **gramática formal** ou um **JSON Schema** durante a geração [5][6][7][8].  
Implementações notáveis incluem **Microsoft Guidance**, **Outlines (Dottxt AI)** e **vLLM Structured Decoding**, demonstrando ganhos concretos de precisão. Estudos apresentados por Raspanti et al. [8] na ACL 2025 reportam **redução média de 62% em erros de parsing** e **melhoria de 18% em precisão lógica** face ao _function calling_ convencional.

#### Pontos fortes

- **Conformidade garantida na origem**, eliminando retrabalho;
    
- **Precisão sintática e lógica superior** [8];
    
- **Baixa latência** — o controlo ocorre durante a geração.
    

#### Limitações

- **Complexidade de engenharia inicial** (definição e manutenção de gramáticas);
    
- **Dependência de runtime**, pois nem todos os fornecedores suportam APIs de gramática;
    
- **Menor flexibilidade criativa**, devido às restrições formais.
    

#### Adequação

Ideal para sistemas de **execução determinística e tempo real**, como o NL→Dash, em que a fidelidade estrutural é crítica e o _schema_ é estável. Segundo BentoML [7], abordagens deste tipo mantêm **latência inferior a 1s (p95)** em geração de JSON até 10k tokens, o que as torna adequadas a contextos interativos.

---

## **3. Comparação das Abordagens**

| **Critério**                   | **Function Calling**        | **Guardrails + JSON Schema** | **Grammar-Constrained Decoding** |
| ------------------------------ | --------------------------- | ---------------------------- | -------------------------------- |
| **Determinismo estrutural**    | Médio (dependente do LLM)   | Alto                         | Muito alto                       |
| **Latência média**             | Baixa                       | Média                        | Baixa                            |
| **Portabilidade**              | Baixa (lock-in)             | Alta                         | Média                            |
| **Complexidade de integração** | Baixa                       | Média                        | Alta                             |
| **Governança e auditoria**     | Limitada                    | Elevada                      | Média                            |
| **Adequação a real-time**      | Alta                        | Média                        | Muito alta                       |
| **Uso típico**                 | Prototipagem e _happy path_ | Produção e conformidade      | Execução determinística          |

---

## **4. Discussão e Tendência Tecnológica**

A evolução destas abordagens mostra uma **migração gradual do controlo pós-geração para o controlo durante a geração** [8][9].  
De forma resumida:

1. **Function Calling (2023–2024)** — prioriza integração rápida e fiabilidade sintática básica;
    
2. **Guardrails + JSON Schema (2024)** — introduz validação e governação formal;
    
3. **Grammar-Constrained Decoding (2025)** — consolida o controlo sintático na origem.
    

No contexto do **NL→Dash**, a fase de geração deve equilibrar **baixa latência** com **taxas de conformidade ≥98%**, de modo a suportar interação contínua entre o utilizador e o sistema.  
A literatura recente sugere que uma **arquitetura híbrida** tende a oferecer os melhores resultados práticos [7][8][9]:

- **Decoding estruturado** para assegurar conformidade imediata com o _schema_;
    
- **Validação posterior (JSON Schema)** para detetar incoerências semânticas e aplicar políticas empresariais.
    

O _function calling_ mantém relevância como camada de integração inicial, mas **não deve ser utilizado isoladamente**, dada a sua vulnerabilidade a erros de estrutura e dependência de fornecedor.

---

## **5. Conclusão**

Entre as três abordagens analisadas, a **combinação de decoding estruturado com validação por JSON Schema** constitui o **compromisso mais equilibrado** entre determinismo, portabilidade e robustez semântica — um modelo que a literatura de 2024–2025 aponta como o padrão emergente para pipelines industriais baseados em LLMs [7][8][9].

Esta estratégia permite:

- **Geração conforme na origem**, minimizando erros de parsing;
    
- **Verificação formal posterior**, independente do fornecedor;
    
- **Latência previsível**, adequada a sistemas interativos e em tempo real.
    

Assim, a fase de **Geração de JSON** do NL→Dash adota um paradigma **“constrained-first, validated-second”**, alinhado com a prática contemporânea em engenharia de IA fiável e determinística.

---

## **Referências**

[1] OpenAI — _Function Calling Guide_ (2025). Disponível em: [https://platform.openai.com/docs/guides/function-calling](https://platform.openai.com/docs/guides/function-calling)  
[2] OpenAI — _Function Calling in the API (Help Center)_, 2025.  
[3] Guardrails AI — _Your Enterprise AI Needs Guardrails_ (2025).  
[4] JSON Schema — _Official Specification_ (2024).  
[5] Microsoft Research — _Guidance: Controlling LM Output_, 2025.  
[6] Dottxt AI — _Outlines: Structured Outputs Complying with JSON Schema_, 2025.  
[7] BentoML — _Structured Decoding in vLLM: A Gentle Introduction_, 2025.  
[8] Raspanti, L. et al., _Grammar-Constrained Decoding Makes LLMs Better Logical Parsers_, _ACL Industry Track 2025_.  
[9] Li et al. (2025). JSONSchemaBench: A Rigorous Benchmark... arXiv:2501.10868.
[10] Wang et al. (2024). HammerBench: Fine-Grained Function-Calling... arXiv:2412.16516. [Cita em 2.1 limitações: "25% ↓ falhas mobile/real-time"]


