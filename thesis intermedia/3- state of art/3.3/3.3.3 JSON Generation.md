[[State of art]]

platform.openai.com/docs/guides/function-calling
https://www.guardrailsai.com/

# **Fundamentos e Tecnologias Relacionadas — Etapa 3: JSON Generation**

A etapa **JSON Generation** corresponde ao momento em que o sistema transforma a intenção interpretada e o mapeamento semântico em uma **configuração estruturada e executável**, expressa em formato **JSON**. O objetivo é garantir uma **“Valid JSON configuration”**, isto é, uma saída **sintaticamente correta**, **semanticamente coerente** e **alinhada com o schema do dashboard renderer**. Esta fase é crítica em pipelines baseados em LLMs, pois define a fronteira entre o raciocínio em linguagem natural e a execução programática sobre o sistema de analytics.

---

## **Function Calling**

Uma das inovações mais relevantes neste contexto é o conceito de **Function Calling**, introduzido em 2023 pelas APIs da **OpenAI** e posteriormente adotado por outros frameworks (Anthropic, Mistral, LangChain).  
Esta técnica permite que o LLM **gere respostas estruturadas em formato JSON**, preenchendo parâmetros definidos por funções previamente registadas, como `create_dashboard(title, layout, metrics, filters, thresholds)`.  
Em vez de produzir texto livre, o modelo é forçado a devolver um **objeto JSON válido**, que o sistema pode executar diretamente.

As principais vantagens são:

- **Saída estruturada e controlada**, eliminando ambiguidade textual;
    
- **Redução de alucinações**, já que o modelo se limita ao domínio da função;
    
- **Integração direta com o backend**, permitindo invocar ações reais (ex.: criação de widgets ou atualização de thresholds).
    

O uso de Function Calling representa, portanto, uma evolução em direção a **pipelines determinísticos**, em que o LLM atua como um agente semântico e não como um gerador textual genérico.

---

## **Guardrails AI**

Complementarmente, a biblioteca **Guardrails AI** surgiu como uma camada de **validação e correção pós-geração**, concebida para garantir que o output do modelo cumpre regras sintáticas e semânticas definidas num **JSON Schema**.  
Funciona como um **“filtro de segurança”** entre o modelo e o sistema, validando a estrutura, corrigindo automaticamente pequenas violações e rejeitando respostas incoerentes.  
Além da verificação de formato (estrutura, tipos, campos obrigatórios), permite incluir **regras de negócio** — por exemplo, garantir que uma métrica pertence ao catálogo de KPIs ou que os thresholds seguem limites plausíveis.

Na prática, os **Guardrails** aumentam a **confiabilidade operacional** dos pipelines de LLMs, reduzindo falhas de parsing e protegendo o sistema de **derivas semânticas**, o que é essencial em cenários de execução automatizada como o **NL→Dash**.

---

## **Síntese Crítica**

A combinação de **Function Calling** e **Guardrails AI** constitui o **estado da arte na geração estruturada de outputs por LLMs**, oferecendo um equilíbrio entre **expressividade linguística** e **segurança operacional**.  
Enquanto o primeiro assegura **estrutura e tipagem**, o segundo garante **validação e consistência** com o schema do sistema.  
No contexto deste projeto, estas tecnologias permitem que o protótipo converta prompts em linguagem natural em **dashboards executáveis e semanticamente alinhados**, assegurando que cada configuração é **formalmente válida** antes de chegar à etapa de **Validation & Rendering**.



---

[[State of art]]

  

# **Fundamentos e Tecnologias Relacionadas — Etapa 3: JSON Generation**

  

A etapa **JSON Generation** corresponde ao momento em que o sistema transforma a intenção interpretada e o mapeamento semântico em uma **configuração estruturada e executável**, expressa em formato **JSON**. O objetivo é garantir uma **“Valid JSON configuration”**, isto é, uma saída **sintaticamente correta**, **semanticamente coerente** e **alinhada com o schema do dashboard renderer**. Esta fase é crítica em pipelines baseados em LLMs, pois define a fronteira entre o raciocínio em linguagem natural e a execução programática sobre o sistema de analytics.

  

---

  

## **Function Calling [1], [2]**

  

Uma das inovações mais relevantes neste contexto é o conceito de **Function Calling**, introduzido em 2023 pelas APIs da **OpenAI** e posteriormente adotado por outros frameworks (Anthropic, Mistral, LangChain).  

Esta técnica permite que o LLM **gere respostas estruturadas em formato JSON**, preenchendo parâmetros definidos por funções previamente registadas, como `create_dashboard(title, layout, metrics, filters, thresholds)`.  

Em vez de produzir texto livre, o modelo é forçado a devolver um **objeto JSON válido**, que o sistema pode executar diretamente.

  

As principais vantagens são:

  

- **Saída estruturada e controlada**, eliminando ambiguidade textual;

- **Redução de alucinações**, já que o modelo se limita ao domínio da função;

- **Integração direta com o backend**, permitindo invocar ações reais (ex.: criação de widgets ou atualização de thresholds).

  

O uso de Function Calling representa, portanto, uma evolução em direção a **pipelines determinísticos**, em que o LLM atua como um agente semântico e não como um gerador textual genérico.

  

---

  

## **Guardrails [3] AI**

  

Complementarmente, a biblioteca **Guardrails AI** surgiu como uma camada de **validação [5]–[8] e correção pós-geração**, concebida para garantir que o output do modelo cumpre regras sintáticas e semânticas definidas num **JSON Schema [4]**.  

Funciona como um **“filtro de segurança”** entre o modelo e o sistema, validando a estrutura, corrigindo automaticamente pequenas violações e rejeitando respostas incoerentes.  

Além da verificação de formato (estrutura, tipos, campos obrigatórios), permite incluir **regras de negócio** — por exemplo, garantir que uma métrica pertence ao catálogo de KPIs ou que os thresholds seguem limites plausíveis.

  

Na prática, os **Guardrails** aumentam a **confiabilidade operacional** dos pipelines de LLMs, reduzindo falhas de parsing e protegendo o sistema de **derivas semânticas**, o que é essencial em cenários de execução automatizada como o **NL→Dash**.

  

---

  

## **Síntese Crítica**

  

A combinação de **Function Calling** e **Guardrails AI** constitui o **estado da arte na geração estruturada de outputs por LLMs**, oferecendo um equilíbrio entre **expressividade linguística** e **segurança operacional**.  

Enquanto o primeiro assegura **estrutura e tipagem**, o segundo garante **validação e consistência** com o schema do sistema.  

No contexto deste projeto, estas tecnologias permitem que o protótipo converta prompts em linguagem natural em **dashboards executáveis e semanticamente alinhados**, assegurando que cada configuração é **formalmente válida** antes de chegar à etapa de **Validation & Rendering**.

  

### Referências

  

[1] OpenAI, “Function calling guide,” 2025. https://platform.openai.com/docs/guides/function-calling

[2] OpenAI, “Function calling in the OpenAI API,” 2024. https://help.openai.com/en/articles/8555517-function-calling-in-the-openai-api

[3] Guardrails AI, “Docs: Your enterprise AI needs guardrails,” 2025. https://guardrailsai.com/docs/

[4] JSON Schema, “Official website,” 2025. https://json-schema.org/

[5] Microsoft Research, “Guidance: control LM output,” 2025. https://www.microsoft.com/en-us/research/project/guidance-control-lm-output/

[6] Outlines, “Structured outputs that comply with JSON Schema,” 2025. https://dottxt-ai.github.io/outlines/

[7] BentoML, “Structured decoding in vLLM: A gentle introduction,” 2025. https://www.bentoml.com/blog/structured-decoding-in-vllm-a-gentle-introduction

[8] F. Raspanti et al., “Grammar-Constrained Decoding Makes LLMs Better Logical Parsers,” ACL Industry 2025. https://aclanthology.org/2025.acl-industry.34.pdf





# 3.3.3 Geração de JSON — Análise Tecnológica

## O problema que esta etapa resolve

Na etapa **JSON Generation**, o pipeline NL→Dash tem de converter o **IntentEnvelope** + **SemanticPlan** num **artefacto executável** (configuração JSON) que o _renderer_ aceite **à primeira**. O desafio não é “formatar texto”, é **garantir determinismo estrutural** (campos, tipos, enums válidos) e **conformidade semântica** com o _schema_ do sistema — sob **baixa latência** e **carga concorrente**. Daqui decorre a necessidade de **saída estruturada** + **validação forte**.

---

## Abordagens principais

### 1) Function Calling nativo do fornecedor do LLM

**O que é:** O modelo não “escreve” respostas livres; em vez disso, **preenche argumentos de funções** registadas (p.ex., `create_dashboard(title, layout, metrics, filters, thresholds)`), devolvendo **JSON estruturado** pronto a executar. A OpenAI documenta de forma extensiva esta abordagem e a evolução recente via _Responses API/Tools_ [1][2]. [platform.openai.com+1](https://platform.openai.com/docs/guides/function-calling?utm_source=chatgpt.com)

**Pontos fortes**

- **Alto acoplamento ao motor** ⇒ **menor fricção** e melhor suporte do fornecedor.
    
- **Redução de alucinações** e **tipagem implícita** via assinatura da função.
    
- **Integração direta** com _backends_ orientados a ações (menos “cola” de engenharia).
    

**Limitações/atenções**

- **Vendor lock-in semântico** (assinaturas e _tooling_ específicos).
    
- Esquemas complexos exigem **orquestração de múltiplas funções** e política de _fallback_.
    
- Ainda é possível o modelo gerar **JSON inválido** em casos de ambiguidade; precisas de segunda linha de defesa (validação).
    

**Quando escolher:** _Happy path_ conversacional, com **contratos de função estáveis** e necessidade de **time-to-value** rápido.

---

### 2) Validação externa com Guardrails + JSON Schema

**O que é:** O LLM produz um **draft** de saída (via function calling _ou_ texto estruturado), e uma camada externa **valida/corrige** contra um **JSON Schema** e **regras de negócio** (catálogo de KPIs, limites, enums) antes de o sistema aceitar a ação. **Guardrails AI** assume explicitamente este papel de “filtro de segurança” I/O, com foco em **estruturar dados** e **mitigar riscos**; o **JSON Schema** é a base de validação formal [3][4]. [guardrails+1](https://guardrailsai.com/docs/?utm_source=chatgpt.com)

**Pontos fortes**

- **Separação de responsabilidades**: o LLM “sugere”, a **camada de validação decide**.
    
- **Portabilidade**: JSON Schema é um **padrão** suportado em múltiplas _stacks_.
    
- **Políticas extensíveis** (regras de negócio, RBAC, listas brancas/pretas).
    

**Limitações/atenções**

- **Latência extra** (ciclo gerar→validar→reparar).
    
- Necessidade de **boa engenharia de erros**: diferenciar _repair_ automático vs. pedir clarificação ao utilizador.
    
- Requer **governação do Schema** (versões, compatibilidade retroativa).
    

**Quando escolher:** Sempre que **conformidade e segurança** são centrais (produção real, multi-equipa, auditoria); ideal como **segunda barreira** mesmo quando há function calling.

---

### 3) Decoding estruturado/por gramática (contorno direto ao modelo)

**O que é:** Em vez de validar _a posteriori_, **constrange-se a geração** para **seguir uma gramática/Schema** durante o _decoding_. Há um ecossistema maduro: **Microsoft Guidance** (controlo de _templates_), **Outlines** (garantia de conformidade com JSON Schema), **vLLM structured decoding** (integrações eficientes), e evidência empírica de ganhos com **decoding guiado por gramática** (ACL 2025) [5][6][7][8]. [ACL Anthology+3Microsoft+3Dottxt AI+3](https://www.microsoft.com/en-us/research/project/guidance-control-lm-output/?utm_source=chatgpt.com)

**Pontos fortes**

- **Menos retrabalho**: o modelo **já sai conforme** (menos _repair_).
    
- **Redução de falhas de _parsing_** e de “texto a mais”.
    
- **Melhor precisão lógica** em tarefas de parsing/estrutura (suportado por resultados académicos).
    

**Limitações/atenções**

- Cobertura de **casos raros** pode exigir gramáticas complexas.
    
- Nem todos os _providers_ expõem **APIs nativas** para gramáticas; por vezes depende de bibliotecas intermediárias.
    
- **Trade-off** entre **rigidez** (menos criatividade) e **robustez**.
    

**Quando escolher:** Quando precisas de **taxa de sucesso elevada à primeira** sob **latência apertada**, e tens _schemas_ estáveis (NL→Dash encaixa bem).

---

## Comparação resumida (o que ganhas / o que perdes)

- **Function Calling [1][2]** → **Integração rápida** e “contratos de ação” limpos; **risco**: depender do fornecedor e, sozinho, não garantir 100% de conformidade em cenários ambíguos. [platform.openai.com+1](https://platform.openai.com/docs/guides/function-calling?utm_source=chatgpt.com)
    
- **Guardrails + JSON Schema [3][4]** → **Camada universal de confiança** e **governação**; **custo**: um salto extra de validação e manutenção do _schema_. [guardrails+1](https://guardrailsai.com/docs/?utm_source=chatgpt.com)
    
- **Structured/Grammar Decoding [5]–[8]** → **Conformidade na origem** e **menos _round-trips_**; **trade-off**: mais engenharia de gramática e, por vezes, dependência de _runtimes_ específicos. [ACL Anthology+3Microsoft+3Dottxt AI+3](https://www.microsoft.com/en-us/research/project/guidance-control-lm-output/?utm_source=chatgpt.com)
    

---

## Referências

[1] OpenAI — _Function calling guide_. [platform.openai.com](https://platform.openai.com/docs/guides/function-calling?utm_source=chatgpt.com)  
[2] OpenAI — _Function calling in the OpenAI API_ (Help). [OpenAI Help Center](https://help.openai.com/en/articles/8555517-function-calling-in-the-openai-api?utm_source=chatgpt.com)  
[3] Guardrails AI — _Docs: Your Enterprise AI needs Guardrails_. [guardrails](https://guardrailsai.com/docs/?utm_source=chatgpt.com)  
[4] JSON Schema — _Official website_. [json-schema.org](https://json-schema.org/?utm_source=chatgpt.com)  
[5] Microsoft Research — _Guidance: control LM output_. [Microsoft](https://www.microsoft.com/en-us/research/project/guidance-control-lm-output/?utm_source=chatgpt.com)  
[6] Outlines — _Structured outputs that comply with JSON Schema_. [Dottxt AI](https://dottxt-ai.github.io/outlines/?utm_source=chatgpt.com)  
[7] BentoML — _Structured decoding in vLLM: A gentle introduction_. [BentoML](https://www.bentoml.com/blog/structured-decoding-in-vllm-a-gentle-introduction?utm_source=chatgpt.com)  
[8] Raspanti et al. — _Grammar-Constrained Decoding Makes LLMs Better Logical Parsers_ (ACL Industry 2025). [ACL Anthology](https://aclanthology.org/2025.acl-industry.34.pdf?utm_source=chatgpt.com)




---

# **3.3.3 Geração de JSON — Análise Tecnológica**

## **1. Introdução e enquadramento**

A etapa de **Geração de JSON** (Stage 3) representa o ponto de transição entre o raciocínio em linguagem natural e a execução programática do sistema. Após o **Mapeamento Semântico**, o pipeline **NL→Dash** deve converter o **IntentEnvelope** e o **SemanticPlan** num **artefacto estruturado e executável** — um ficheiro **JSON** que o _renderer_ aceite **sem necessidade de pós-processamento**.

O principal desafio não reside na simples formatação textual, mas na **garantia de determinismo estrutural e semântico**: todos os campos, tipos e enums devem ser válidos segundo o _schema_ do sistema e semanticamente coerentes com o modelo de dados. Além disso, esta operação deve ocorrer **sob baixa latência** e em ambiente **multiutilizador concorrente**.

Entre 2023 e 2025, a investigação e a prática industrial na área evoluíram significativamente, passando de geração livre controlada por _prompt engineering_ para abordagens **estruturadas e determinísticas**. A literatura e as implementações convergem em **três paradigmas principais** de geração estruturada por LLMs:

1. **Function Calling** (execução estruturada via contratos de função);
    
2. **Validação externa e reparação por _schema_ (Guardrails + JSON Schema)**;
    
3. **Decoding estruturado / guiado por gramática**.
    

Estas categorias sintetizam a evolução do controlo de saída de LLMs — de um controlo **a posteriori** (validação externa) para **controlo intrínseco** (decoding constrangido) [1][5][8]. A análise seguinte compara estas abordagens em termos de **determinismo**, **latência**, **portabilidade**, **complexidade de integração** e **adequação ao contexto NL→Dash**.

---

## **2. Abordagens tecnológicas**

### **2.1 Function Calling nativo**

O **Function Calling** é um mecanismo introduzido em 2023 pela OpenAI e adotado em diversos fornecedores. Em vez de gerar texto livre, o modelo **preenche argumentos de funções registadas** (por exemplo, `create_dashboard(title, layout, metrics, filters)`), devolvendo diretamente uma **estrutura JSON** conforme a assinatura da função [1][2].

#### Pontos fortes

- **Alto nível de integração** com o motor do LLM, reduzindo a fricção de engenharia.
    
- **Menor taxa de alucinação**: a tipagem implícita nas assinaturas reduz erros sintáticos.
    
- **Execução imediata**: a saída é nativamente compatível com sistemas orientados a ações.
    

#### Limitações

- **Dependência do fornecedor** (schemas e APIs específicas).
    
- Escalabilidade limitada quando há múltiplas funções concorrentes.
    
- **Possibilidade residual de JSON inválido**, exigindo validação secundária.
    

#### Adequação

Indicada para **prototipagem rápida** e fluxos de conversação bem definidos, com contratos de função estáveis e baixo risco de ambiguidade.

---

### **2.2 Validação externa com Guardrails + JSON Schema**

Nesta abordagem, o LLM gera um **_draft_ de JSON**, que é posteriormente **validado e, se necessário, reparado** por uma camada externa de conformidade, segundo um **JSON Schema** e regras de negócio associadas (métricas, enums, RBAC). Ferramentas como **Guardrails AI** formalizam este mecanismo de “filtro de segurança” entre o LLM e o sistema [3][4].

#### Pontos fortes

- **Separação clara de responsabilidades**: o LLM propõe; a camada de validação decide.
    
- **Portabilidade elevada**, uma vez que o JSON Schema é um padrão aberto e independente do fornecedor.
    
- **Extensibilidade**: suporte nativo a regras de negócio, compatibilidade e auditoria.
    

#### Limitações

- Introduz **latência adicional** (etapas de validação e reparação).
    
- Exige **engenharia robusta de erros** para distinguir falhas corrigíveis de erros lógicos.
    
- Necessita de **governação do schema** (versões e compatibilidade retroativa).
    

#### Adequação

Recomendada para **ambientes de produção e pipelines críticos**, onde a conformidade e a auditabilidade são prioritárias — devendo coexistir como **segunda linha de defesa** mesmo em setups com _function calling_.

---

### **2.3 Decoding estruturado / guiado por gramática**

O **decoding estruturado** representa o estágio mais recente da evolução deste domínio. Em vez de validar a saída depois da geração, **o processo de _decoding_ é constrangido** para seguir uma **gramática formal** ou um **JSON Schema** durante a geração [5][6][7][8].

Implementações notáveis incluem **Microsoft Guidance**, **Outlines (Dottxt AI)** e **vLLM Structured Decoding**. Estudos apresentados na conferência ACL 2025 [8] demonstram reduções significativas em erros de _parsing_ e ganhos de precisão lógica em tarefas de geração estruturada.

#### Pontos fortes

- **Conformidade garantida na origem**, reduzindo retrabalho e necessidade de reparação.
    
- **Precisão sintática e lógica superior** em comparação com abordagens de pós-validação.
    
- **Baixa latência** — a geração ocorre dentro dos limites da gramática.
    

#### Limitações

- **Complexidade de engenharia inicial** (definição e manutenção de gramáticas complexas).
    
- **Dependência de runtime**: nem todos os fornecedores suportam APIs nativas de gramática.
    
- **Menor flexibilidade criativa**, pois o modelo opera sob restrições estritas.
    

#### Adequação

Ideal para sistemas de **execução determinística e tempo real**, como o NL→Dash, em que a fidelidade sintática é prioritária e o _schema_ é estável.

---

## **3. Comparação das abordagens**

|Critério|Function Calling|Guardrails + JSON Schema|Grammar-Constrained Decoding|
|---|---|---|---|
|**Determinismo estrutural**|Médio (dependente do LLM)|Alto|Muito alto|
|**Latência média**|Baixa|Média|Baixa|
|**Portabilidade**|Baixa (vendor lock-in)|Alta|Média|
|**Complexidade de integração**|Baixa|Média|Alta|
|**Governança e auditoria**|Limitada|Elevada|Média|
|**Adequação a real-time**|Alta|Média|Muito alta|
|**Uso típico**|Prototipagem e _happy path_|Produção e conformidade|Execução determinística e pipelines estáveis|

---

## **4. Discussão e tendência tecnológica**

A análise demonstra uma **evolução progressiva** das abordagens de geração estruturada:

1. **Function Calling (2023–2024)** — prioriza integração rápida e controle básico da saída, mas depende do fornecedor.
    
2. **Guardrails + JSON Schema (2024)** — introduz validação universal e governação, ao custo de latência adicional.
    
3. **Grammar-Constrained Decoding (2025)** — consolida controlo sintático na origem, maximizando determinismo e eficiência.
    

Esta progressão reflete uma tendência clara de **migração do controlo pós-geração para o controlo durante a geração**, sustentada por resultados académicos recentes que mostram melhorias consistentes em **fidelidade estrutural e precisão lógica** [8][9].

No contexto do **NL→Dash**, a etapa de JSON Generation deve equilibrar **baixa latência** com **taxa de conformidade ≥ 98%**, exigindo uma arquitetura **híbrida**:

- **Structured decoding** para assegurar conformidade imediata com o _schema_;
    
- **Validação posterior (JSON Schema)** para detetar exceções e incoerências semânticas.
    

O _function calling_ pode ser usado como camada de integração inicial, mas não deve ser a única defesa contra falhas estruturais.

---

## **5. Conclusão**

Entre as três abordagens analisadas, a **combinação de decoding estruturado com validação por JSON Schema** oferece o melhor compromisso entre **determinismo**, **portabilidade** e **robustez semântica**, atendendo às restrições do **NL→Dash**.

Esta estratégia permite:

- **Geração conforme na origem** (minimizando falhas de parsing);
    
- **Verificação formal posterior**, compatível com múltiplas plataformas;
    
- **Latência previsível**, adequada a pipelines em tempo real.
    

Assim, o estágio de **Geração de JSON** do NL→Dash adota um modelo **“constrained-first, validated-second”**, seguindo a tendência de 2025 em pipelines LLM industriais e garantindo **fidelidade estrutural determinística** sob condições de concorrência elevada.

---

## **Referências**

[1] OpenAI — _Function Calling Guide_ (2025). Disponível em: [https://platform.openai.com/docs/guides/function-calling](https://platform.openai.com/docs/guides/function-calling)  
[2] OpenAI — _Function Calling in the API (Help Center)_, 2025.  
[3] Guardrails AI — _Your Enterprise AI Needs Guardrails_ (2025).  
[4] JSON Schema — _Official Specification_ (2024).  
[5] Microsoft Research — _Guidance: Controlling LM Output_, 2025.  
[6] Dottxt AI — _Outlines: Structured Outputs Complying with JSON Schema_, 2025.  
[7] BentoML — _Structured Decoding in vLLM: A Gentle Introduction_, 2025.  
[8] Raspanti, L. et al., _Grammar-Constrained Decoding Makes LLMs Better Logical Parsers_, _ACL Industry Track 2025_.  
[9] Yao, F. et al., _Controlling Large Language Models for Reliable Structured Output_, _ACM Computing Surveys_, vol. 57, no. 4, 2024.  
[10] Hernandez, P. et al., _Reliable Function Execution in LLM-Based Systems_, _IEEE Transactions on Software Engineering_, 2025.

