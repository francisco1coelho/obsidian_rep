[[State of art]]

platform.openai.com/docs/guides/function-calling
https://www.guardrailsai.com/

# **Fundamentos e Tecnologias Relacionadas — Etapa 3: JSON Generation**

A etapa **JSON Generation** corresponde ao momento em que o sistema transforma a intenção interpretada e o mapeamento semântico em uma **configuração estruturada e executável**, expressa em formato **JSON**. O objetivo é garantir uma **“Valid JSON configuration”**, isto é, uma saída **sintaticamente correta**, **semanticamente coerente** e **alinhada com o schema do dashboard renderer**. Esta fase é crítica em pipelines baseados em LLMs, pois define a fronteira entre o raciocínio em linguagem natural e a execução programática sobre o sistema de analytics.

---

## **Function Calling**

Uma das inovações mais relevantes neste contexto é o conceito de **Function Calling**, introduzido em 2023 pelas APIs da **OpenAI** e posteriormente adotado por outros frameworks (Anthropic, Mistral, LangChain).  
Esta técnica permite que o LLM **gere respostas estruturadas em formato JSON**, preenchendo parâmetros definidos por funções previamente registadas, como `create_dashboard(title, layout, metrics, filters, thresholds)`.  
Em vez de produzir texto livre, o modelo é forçado a devolver um **objeto JSON válido**, que o sistema pode executar diretamente.

As principais vantagens são:

- **Saída estruturada e controlada**, eliminando ambiguidade textual;
    
- **Redução de alucinações**, já que o modelo se limita ao domínio da função;
    
- **Integração direta com o backend**, permitindo invocar ações reais (ex.: criação de widgets ou atualização de thresholds).
    

O uso de Function Calling representa, portanto, uma evolução em direção a **pipelines determinísticos**, em que o LLM atua como um agente semântico e não como um gerador textual genérico.

---

## **Guardrails AI**

Complementarmente, a biblioteca **Guardrails AI** surgiu como uma camada de **validação e correção pós-geração**, concebida para garantir que o output do modelo cumpre regras sintáticas e semânticas definidas num **JSON Schema**.  
Funciona como um **“filtro de segurança”** entre o modelo e o sistema, validando a estrutura, corrigindo automaticamente pequenas violações e rejeitando respostas incoerentes.  
Além da verificação de formato (estrutura, tipos, campos obrigatórios), permite incluir **regras de negócio** — por exemplo, garantir que uma métrica pertence ao catálogo de KPIs ou que os thresholds seguem limites plausíveis.

Na prática, os **Guardrails** aumentam a **confiabilidade operacional** dos pipelines de LLMs, reduzindo falhas de parsing e protegendo o sistema de **derivas semânticas**, o que é essencial em cenários de execução automatizada como o **NL→Dash**.

---

## **Síntese Crítica**

A combinação de **Function Calling** e **Guardrails AI** constitui o **estado da arte na geração estruturada de outputs por LLMs**, oferecendo um equilíbrio entre **expressividade linguística** e **segurança operacional**.  
Enquanto o primeiro assegura **estrutura e tipagem**, o segundo garante **validação e consistência** com o schema do sistema.  
No contexto deste projeto, estas tecnologias permitem que o protótipo converta prompts em linguagem natural em **dashboards executáveis e semanticamente alinhados**, assegurando que cada configuração é **formalmente válida** antes de chegar à etapa de **Validation & Rendering**.
